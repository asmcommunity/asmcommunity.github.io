<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8" />
  <title>Speed of addressing modes - Forums - ASM Community</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" />
  <link rel="canonical" href="../?id=24992" />
     </head>
 <body>
  <div id="header">
   <h1><a href="../../../">ASM Community</a></h1>
  </div>
  <div id="content">
   <p class="breadcrumbs"><a href="../../../">Home</a> &raquo; <a href="../../">Forums</a> &raquo; <a href="../../board/?id=3">MAIN</a> &raquo; <a href="../?id=24992">Speed of addressing modes</a></p>
   <div class="post" id="post-182983">
    <div class="subject"><a href="#post-182983">Speed of addressing modes</a></div>
    <div class="body">Hi all,<br /><br />I have several situations where I can choose between these two forms of memory access:<br /><pre><code><br />mov eax, <br />mov eax, <br /></code></pre><br />The first instruction is three bytes long, while the second is seven bytes long. But on the other hand, the first one uses up a precious general purpose register and needs to read esi first, while the second instruction can execute immediately.<br /><br />So, which one is better? The static address is used several times, so loading it into esi can be neglected.<br /><br />Thanks,<br /><br />c0d1f1ed</div>
    <div class="meta">Posted on 2006-07-05 14:20:30 by C0D1F1ED</div>
   </div>
   <div class="post" id="post-183009">
    <div class="subject"><a href="#post-183009">Re: Speed of addressing modes</a></div>
    <div class="body">- Using the registers is almost always faster and it&#39;s always shorter<br />- Shorter instructions are almost always faster (than their longer equivalents).<br /><br />The CPU does everything within its ultra-small memory area called &#39;registers&#39;. Caclulating the effective address from the argument is no different. It&#39;s faster to add 1 register to another, than copy the argument to a temporary register, then add it to another.<br /><br />At least theoretically that is, because nowadays CPU&#39;s pre-decode instructions, so simply changing from 1 option to another won&#39;t make any noticable difference (in most cases). Everything depends on the whole code, not on its micro-parts. First optimize the algorithm (mathematically), then try to write it using the most suitable data structures, then optimize all functions, and then and only then try to &#39;cut&#39; some instructions. But first 2 optimizations give you ~80% of all you can get, in most cases. It&#39;s best seen in Intel&#39;s JPEG library: Plain IDCT algorithm executes in 30s on my CPU (1024x768x24bit image). Aggressively Optimized plain algorithm executes in 3s. AA&amp;N algorithm (mathematically changed variant, which produces same results with CPU-friendly operations) executes in ~100-140ms. The one implemented by Intel in their library (strongly MMX- and SSE-optimized) executes in ~70-80ms. As you can see, you get 0.00(3)* of the original performance from optimizing the algorithm itself, and only ~0.635 from optimizing the code.<br /><br /><br /><br />So the lesson is: don&#39;t bother about instructions, unless your algorithm is perfect and you use ideally-suited data structures and functions.<br /><br /><br /><br /><br />*1.0 means &#39;no change&#39;, 0.5 means &#39;2 times faster&#39;, 0.1 means &#39;10 times faster&#39;, 0.00(3) means &#39;300 times faster&#39;.</div>
    <div class="meta">Posted on 2006-07-06 02:08:27 by ti_mo_n</div>
   </div>
   <div class="post" id="post-183084">
    <div class="subject"><a href="#post-183084">Re: Speed of addressing modes</a></div>
    <div class="body">Haha I thought that&#39;s what computer scientist have been preaching? Using a superior algorithm is definitely the right way to go. <br /><br />Personally I think it is better to make use of register, but it is best you test it out with a profiler yourself.</div>
    <div class="meta">Posted on 2006-07-07 08:31:09 by roticv</div>
   </div>
   <div class="post" id="post-183147">
    <div class="subject"><a href="#post-183147">Re: Speed of addressing modes</a></div>
    <div class="body"><div class="quote">It&#39;s faster to add 1 register to another, than copy the argument to a temporary register, then add it to another.</div><br />Doesn&#39;t the immediate address enter the execution pipeline directly? x86 micro-instructions are very long so I&#39;d expect this to be included.<br /><div class="quote">At least theoretically that is, because nowadays CPU&#39;s pre-decode instructions...</div><br />Only the Pentium 4 uses a trace cache. The soon to be released Intel Core 2 Duo processor won&#39;t even use it any more.<br /><div class="quote">So the lesson is: don&#39;t bother about instructions, unless your algorithm is perfect and you use ideally-suited data structures and functions.</div><br />My algorithm is perfect. 8) It has a lot of &#39;global&#39; data though (tables with constants and such), so I have the option to encode the addresses into the memory operations directly or work indirectly with a register.<br /><br />So I want to know if anyone has any specific experience with different addressing modes. It&#39;s quite likely that it doesn&#39;t have much of an influence, but I want to ask anyway...</div>
    <div class="meta">Posted on 2006-07-08 08:46:10 by C0D1F1ED</div>
   </div>
   <div class="post" id="post-183149">
    <div class="subject"><a href="#post-183149">Re: Speed of addressing modes</a></div>
    <div class="body">I agree on &quot;everything depends on the whole code...<br />so if your algo could be speed up in other parts by use esi or not?<br />I was thinking a third option if your code looks about this<br />you have 7 adresses of adress+ecx*4, the other is 1 adress2+ecx*4<br />rework it to use only ecx and  instead and initialize ecx before loop just once 4*ecx+adress<br />in loop exchange add ecx,1 to add ecx,4<br />cmp ecx, check if equal endadress<br /><br />I myself like to use mov ,eax / add ecx,4 over<br />mov ,eax / add ecx,1<br />its easier to customize to any stepping and easier to type, if you target PIV&#39;s, you anyway use add instead of inc<br /><br />in theory, wouldnt a access from indirect register few times, over dependency on calculate adress+ecx*4 or esi+ecx*4 be faster?<br />especially esi+ecx*4, as cpu cant count on esi being constant<br /><br /><br /></div>
    <div class="meta">Posted on 2006-07-08 09:33:05 by daydreamer</div>
   </div>
   <div class="post" id="post-183153">
    <div class="subject"><a href="#post-183153">Re: Speed of addressing modes</a></div>
    <div class="body">Another voice sings the praise of the &quot;whole code&quot; concept. Another thing to think about is the order and alignment of data in the DATA section of your program. The caching algorithm, especially on p6 architecture is optimized for DWORD aligned data and cache reads on contiguous data (size is processor specific). So if you have read from an address close to the one containing your memory offset the read ahead algorithm functions more effectively, speeding things up. As for register or memory, the internal cache of the processor is just as fast as a register and with read ahead and well thought out code structure the memory based address will be ready before it is needed so the savings by using a register are negligible.<br /><br />Donkey</div>
    <div class="meta">Posted on 2006-07-08 10:40:27 by donkey</div>
   </div>
   <div class="post" id="post-183204">
    <div class="subject"><a href="#post-183204">Re: Speed of addressing modes</a></div>
    <div class="body"><div class="quote">(...)</div><br />You got me wrong. I&#39;m not talking about caching already-decoded instructions, which doesn&#39;t speed up very much (that&#39;s why it&#39;s been deprecated). I&#39;m talking about pre-decoding process. CPU decodes instructions into micro-operations and executes them. Nowadays CPUs decode ahead in parallel with execution. Trace cache wasn&#39;t very good, because chaotic code had to be decoded and stored inside the cache every time it was executed. Normal L1 cache is better, because it stores chaotic code itself, ready to be decoded and executed. Immediate address must be decoded and stored inside a temporary register. Then it can be added to anything else. It&#39;s slower than adding 2 registers. The main idea behind registers is to add the CPU a super-fast memory area. That&#39;s why we have registers in the first place. We could as well operate on immediates and memory operands, like in JAVA, and other HLL*.<br /><br /><div class="quote">My algorithm is perfect. 8) It has a lot of &#39;global&#39; data though (tables with constants and such), so I have the option to encode the addresses into the memory operations directly or work indirectly with a register.</div><br />So you should bother about data structures :)<br /><br /><div class="quote">So I want to know if anyone has any specific experience with different addressing modes. It&#39;s quite likely that it doesn&#39;t have much of an influence, but I want to ask anyway...</div><br />If you want a simple and plain answer, then: use the registers. They are better.<br /><br />The whole rant above was to explain you that nowadays CPUs are <strong>VERY</strong> complicated and it&#39;s hard to predict whether &#39;this&#39; or &#39;that&#39; will be better. There is really no simple answer whether you should use &#39;this&#39; or &#39;that&#39;. It depends on the algorithm, data organization, and even the place inside the code. But yes - try to use registers as often as you can. Try to desing your algorithms and data structures the way they use the registers as often as they can. The registers reside inside the most inner part of the CPU. That&#39;s why there is so few of them. Intel or AMD could add 512 128-bit registers (or even more) to their CPUs if they wanted to, but then such CPUs would cost...¦nbsp; ugh O_O¦nbsp; ¦nbsp;<strong>TOO MUCH</strong> and they really wouldn&#39;t be worth the price, because we would require incredibly intelligent compilers to utilize those CPUs&#39; full power (most of the world codes in HLLs).<br /><br /><br /><br /><br />*Explaination about this &quot;java and other hlls&quot;: I know that HLLs get compiled and assembled and then they DO USE registers. What i mean is the languages &gt;themselves&lt;. They don&#39;t use registers: only immediates and memory operands.</div>
    <div class="meta">Posted on 2006-07-09 02:15:45 by ti_mo_n</div>
   </div>
   <div class="post" id="post-183313">
    <div class="subject"><a href="#post-183313">Re: Speed of addressing modes</a></div>
    <div class="body">You just made me think for a minute... Why aren&#39;t compilers more intelligent than they are? I know it&#39;s possible to create a much more intelligent compiler than we have now, especially with all the advances in AI that we have... Maybe someone (I&#39;m not directly suggesting anyone here) should go out and use AI to make a compuler that can actually optimize stuff the way an assembly coder iptimizes, and maybe even better (figure out how to make an algorithm work better, etc.)</div>
    <div class="meta">Posted on 2006-07-10 05:12:41 by Bobbias</div>
   </div>
   <div class="post" id="post-183533">
    <div class="subject"><a href="#post-183533">Re: Speed of addressing modes</a></div>
    <div class="body">Instead of just guessing or threading on experience, I made a little benchmark on <br /><pre><code><br />; code 1, takes &lt;result1&gt; cycles<br />mov esi,offset offs1<br />mov edx,1000<br />@@:<br />	mov eax,edx<br />	and eax,3<br />	dec edx<br />	mov ,eax<br />jnz @B<br /></code></pre><br />against<br /><pre><code><br />mov edx,1000<br />@@:<br />	mov eax,edx<br />	and eax,3<br />	dec edx<br />	mov offs1,eax<br />jnz @B<br /></code></pre><br />Ran it at realtime-priority-class dozens of times, and the results are always:<br /><pre><code><br />result1 = 3045<br />result2 = 3044<br />result1 = 3045<br />result2 = 3045<br />result1 = 3045<br />result2 = 3045<br />result1 = 3046<br />result2 = 3046<br />result1 = 3045<br />result2 = 3046<br />result1 = 3046<br />result2 = 3046<br /></code></pre><br />In other words, at least on <em>my</em> cpu, <em>this</em> code performs like this.<br />Sempron 2200+. I think it&#39;s best to actually benchmark <em>your</em> code when feeling such doubts, and select the faster implementation (you might need to test it on different cpus). <br /><br />Bobbias: I think GCC4.1 boasts with it, - they&#39;re doing it by adding an &quot;abstract assembler&quot; iirc between the *c++.exe and *as.exe. But anyway, I hope the need for asm is always present. </div>
    <div class="attachments">Attachments:
     <ul>
      <li><a href="../../attachments/?id=1854" target="_blank">ZZZ_TEST2.zip</a></li>
     </ul>
    </div>
    <div class="meta">Posted on 2006-07-14 17:14:32 by Ultrano</div>
   </div>
   <div class="post" id="post-183957">
    <div class="subject"><a href="#post-183957">Re: Speed of addressing modes</a></div>
    <div class="body"><div class="quote"><br />You just made me think for a minute... Why aren&#39;t compilers more intelligent than they are? I know it&#39;s possible to create a much more intelligent compiler than we have now, especially with all the advances in AI that we have... Maybe someone (I&#39;m not directly suggesting anyone here) should go out and use AI to make a compuler that can actually optimize stuff the way an assembly coder iptimizes, and maybe even better (figure out how to make an algorithm work better, etc.)<br /></div><br /><br />It is well within our technological state to create a compiler that generates perfectly optimized code. However, the algorithms to do so are NP-Complete and generating the perfectly optimized program would take a *very* long time (i.e., longer than the age of the universe).&nbsp; Therefore, such compilers won&#39;t be very practical to use :-)<br />Cheers,<br />Randy Hyde<br /></div>
    <div class="meta">Posted on 2006-07-24 09:00:53 by rhyde</div>
   </div>
   <div class="post" id="post-183970">
    <div class="subject"><a href="#post-183970">Re: Speed of addressing modes</a></div>
    <div class="body">I&#39;d say use the register.<br />In simple code it doesn&#39;t make much difference but with more complex code the CPU is parallel decoding typically 16 byte lines of data and the higher the code density in those 16 bytes, the more scope it has to do functions in parallel.<br />If you have 7 byte instruction then you&#39;ll only have room for 2 or 3 instructions, with 3-byte instruction you&#39;ll have room for 5 or 6, that&#39;s nearly 3 times the code density and 3 times the opportuinity for the CPU to find savings.<br /><br />Paul.</div>
    <div class="meta">Posted on 2006-07-24 11:48:04 by pdixon</div>
   </div>
  </div>
 </body>
</html>