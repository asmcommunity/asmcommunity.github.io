<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8" />
  <title>Text analysis - Forums - ASM Community</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" />
  <link rel="canonical" href="../?id=2736" />
     </head>
 <body>
  <div id="header">
   <h1><a href="../../../">ASM Community</a></h1>
  </div>
  <div id="content">
   <p class="breadcrumbs"><a href="../../../">Home</a> &raquo; <a href="../../">Forums</a> &raquo; <a href="../../board/?id=3">MAIN</a> &raquo; <a href="../?id=2736">Text analysis</a></p>
   <div class="post" id="post-17419">
    <div class="subject"><a href="#post-17419">Text analysis</a></div>
    <div class="body">Hi, <br />Have someone seen a program with open source that automatically creates the abstract. Abstract is a set of the proposals of the abstracted text, which one contain the key terms of the contents.  So, that mean: I have a big file and program must create a scheme of it.</div>
    <div class="meta">Posted on 2002-01-03 12:37:06 by Maestro</div>
   </div>
   <div class="post" id="post-17515">
    <div class="subject"><a href="#post-17515">Text analysis</a></div>
    <div class="body">I can say honestly, from my experience of this board... No..<br /><br />But then again, i dont really know what your getting at :confused:<br /><br />Abstracts are to me, a short introduction to an essay, which covers the broadest topics only...   <br /><br />Your asking for a program that broadly discribes text documents??<br /><br />Or am i off base here?<br /><br />NaN</div>
    <div class="meta">Posted on 2002-01-04 00:47:12 by NaN</div>
   </div>
   <div class="post" id="post-17519">
    <div class="subject"><a href="#post-17519">Text analysis</a></div>
    <div class="body">If I understand you correctly:<br />Well, I know these programs exist, but they're probably not open source and probably written in C(++). Besides, I don't believe any of them are good (precise) enough to be used for anything else then making descriptions for search engines. <br /><br />If I misunderstood you and you mean:<br /><div class="quote">Has someone seen a program with open source that automatically creates an index of a document. A index is a list of the keywords (headings and subheadings) in the indexed text.</div> <br />Every good word processor can do that, and I believe Corel's suite is open source (but C++ of course).<br />Sorry if I'm insulting your langauge skills with this second option, but in the &quot;New post&quot; screen I couldn't see where you're from...<br />Edit: You didn't specify your location at all  :grin:</div>
    <div class="meta">Posted on 2002-01-04 02:03:10 by Qweerdy</div>
   </div>
   <div class="post" id="post-17683">
    <div class="subject"><a href="#post-17683">Text analysis</a></div>
    <div class="body">No, I am sorry for my bad English, but I can't describe what I need in two words. So, when you read books/articles you see a great deal of information. Some information you need, some don't. But you need to read it all before you can make a decision what info you need. It will be great if a program can create a short description of what is this paper about (about 1 sentence on every 6-7). It will be great.<br /><br />About Corel sources: where have you seen them?</div>
    <div class="meta">Posted on 2002-01-05 04:54:08 by Maestro</div>
   </div>
   <div class="post" id="post-17695">
    <div class="subject"><a href="#post-17695">Text analysis</a></div>
    <div class="body">You'd get more mileage out of studying (and practising) some good reading<br />techniques.  I gave the Photoreading course by Paul Scheele a try and it was<br />quite useful (although not living up to it's advertised hype of<br />sub-consciously reading at 25,000 words per minute).  It gives some good<br />advice on how to mentally and physically prepare for a heavy reading session,<br />how to go about determining whether or not the literature you have is relevant<br />to the information you're seeking, how to structure the reading of lengthy<br />documents without getting fatigued and losing interest etc..  It's fantastic<br />if you're into dry, lengthy, technical material as I am. <br /><br />It comes with a money back gaurantee too.  Check it out:<br /><a target="_blank" href="http://www.learningstrategies.com/PhotoReading/Home.html">http://www.learningstrategies.com/PhotoReading/Home.html</a><br /><br />As for doing it programmaticly, you could maybe have a database of catagories<br />and keywords, then have a simple parser to run through the document, generate<br />tokens to send to an analyzer that generates statistics based on the query you<br />requested.  I'm sure there's source code available that does something like that.<br /><br />To go beyond that would be asking the machine to not only to analyse the<br />grammar but it's semantics, I've not seen anything that could do this in the<br />way you want.  Think about how redunant English (and every other all spoken<br />language) is and the complex grammar productions rules you would have to<br />create.  My advice is to go for the less accurate but more practical<br />statistical approach.<br /><br />Have a look at: <a target="_blank" href="http://www.antlr.org/">http://www.antlr.org/</a><br /><br />Cheers,<br />Boggy</div>
    <div class="meta">Posted on 2002-01-05 06:40:09 by Boggy</div>
   </div>
  </div>
 </body>
</html>