<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8" />
  <title>How to download a web page to a .txt file - Forums - ASM Community</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" />
  <link rel="canonical" href="../?id=30540" />
     </head>
 <body>
  <div id="header">
   <h1><a href="../../../">ASM Community</a></h1>
  </div>
  <div id="content">
   <p class="breadcrumbs"><a href="../../../">Home</a> &raquo; <a href="../../">Forums</a> &raquo; <a href="../../board/?id=3">MAIN</a> &raquo; <a href="../?id=30540">How to download a web page to a .txt file</a></p>
   <div class="post" id="post-214289">
    <div class="subject"><a href="#post-214289">How to download a web page to a .txt file</a></div>
    <div class="body">Hi everyone!<br /><br />I need your help, I don&#039;t know how can I download a web page to a .txt file.<br />I mean, I want to download all the text contained on a web page into a .txt file.<br />The only thing that comes to my mind is URLDownloadToFile, but seems like it just downloads files.<br /><br />It is possible to search some text on a web page from my program? How?<br /><br />Thanks in advance!</div>
    <div class="meta">Posted on 2011-04-15 22:54:15 by GermainR27</div>
   </div>
   <div class="post" id="post-214290">
    <div class="subject"><a href="#post-214290">Re: How to download a web page to a .txt file</a></div>
    <div class="body">A &quot;web page&quot; is a &quot;file&quot;, no?<br /><br />I know how to do it at a lower level. I guess for &#039;doze you&#039;d need &quot;WSAStartup&quot; first. Then &quot;socket&quot;, &quot;connect&quot;, &quot;send&quot; a &quot;get&quot; request - has to be properly formatted - and &quot;recv&quot; what it sends ya. I have an example written by Nathan Baker (using the NASMX package) which I have &quot;modified&quot; by adding a &quot;fakeapi.asm&quot; file which can be linked with it to make it run on Linux (same source code). As such, it&#039;s oversimplified and a little &quot;weird&quot;. I&#039;ll post it if you can&#039;t find anything more suitable.<br /><br />Best,<br />Frank<br /><br /></div>
    <div class="meta">Posted on 2011-04-16 12:15:18 by fbkotler</div>
   </div>
   <div class="post" id="post-214291">
    <div class="subject"><a href="#post-214291">Re: How to download a web page to a .txt file</a></div>
    <div class="body">Frank,<br />I think he means he wants to strip the HTML out of the document leaving only visible text (sorta like using &#039;links -dump $URL&#039;).<br /><br />Germain<br />That being said, this is not a trivial task and even people writing it in languages like PERL with advance parsing usually resort to &quot;hacks&quot; to accomplish what they want. That being said, I would look into the PCRE library to help you in getting the results you want. If you&#039;re a little braver, I&#039;d say go check out the source for links2 curses based web browser and see how it implements the -dump command. :)<br /><br />Regards,<br />Bryant Keller</div>
    <div class="meta">Posted on 2011-04-16 15:22:19 by Synfire</div>
   </div>
   <div class="post" id="post-214292">
    <div class="subject"><a href="#post-214292">Re: How to download a web page to a .txt file</a></div>
    <div class="body">Ah! Yes, that&#039;ll take some parsing. Not so easy. How much would you lose if you just dumped everything between &#039;&lt;&#039; and &#039;&gt;&#039;?<br /><br />Best,<br />Frank<br /><br /></div>
    <div class="meta">Posted on 2011-04-16 15:40:35 by fbkotler</div>
   </div>
   <div class="post" id="post-214293">
    <div class="subject"><a href="#post-214293">Re: How to download a web page to a .txt file</a></div>
    <div class="body"><div class="quote"><br />Frank,<br />I think he means he wants to strip the HTML out of the document leaving only visible text (sorta like using &#039;links -dump $URL&#039;).<br /><br />Germain<br />That being said, this is not a trivial task and even people writing it in languages like PERL with advance parsing usually resort to &quot;hacks&quot; to accomplish what they want. That being said, I would look into the PCRE library to help you in getting the results you want. If you&#039;re a little braver, I&#039;d say go check out the source for links2 curses based web browser and see how it implements the -dump command. :)<br /><br />Regards,<br />Bryant Keller<br /></div><br /><br />Yeah, that is exacly what I want to do!</div>
    <div class="meta">Posted on 2011-04-16 19:57:36 by GermainR27</div>
   </div>
   <div class="post" id="post-214304">
    <div class="subject"><a href="#post-214304">Re: How to download a web page to a .txt file</a></div>
    <div class="body"><div class="quote">How much would you lose if you just dumped everything between &#039;&lt;&#039; and &#039;&gt;&#039;?</div><br /><br />Yeah, that probably would work in best cases. Truthfully, he&#039;ll probably want to completely ignore the &lt;head&gt;&lt;/head&gt; &lt;style&gt;&lt;/style&gt; and &lt;script&gt;&lt;/script&gt; sections first, then rescan stripping out all tags. A problem with this can be when people improperly use &lt;&#039;s or &gt;&#039;s in source instead of &amp;lt; or &amp;gt;, but that could be chalked up to not supporting poorly developed HTML code.</div>
    <div class="meta">Posted on 2011-04-18 12:34:15 by Synfire</div>
   </div>
   <div class="post" id="post-214305">
    <div class="subject"><a href="#post-214305">Re: How to download a web page to a .txt file</a></div>
    <div class="body">Yeah... not really as simple as that. I wasn&#039;t thinking clearly (shocked, I tell ya!). The &quot;download&quot; part isn&#039;t too tough. Stripping the &quot;html&quot; to leave &quot;clean text&quot; is more complicated - especially dealing with any &quot;bad html&quot;, as you point out!<br /><br />Any progress with it, GermainR27?<br /><br />Best,<br />Frank<br /><br /></div>
    <div class="meta">Posted on 2011-04-18 14:15:21 by fbkotler</div>
   </div>
   <div class="post" id="post-214306">
    <div class="subject"><a href="#post-214306">Re: How to download a web page to a .txt file</a></div>
    <div class="body">You are better off using a premade lib for this (there are a few out there I think), One of my apps, I had to deal with a page returned from a server...&nbsp; I just parsed the HTML for what I needed.... it is a real PITA to parse HTML since nobody seems to follow a standard... since most browsers fix bad tags on the fly.... you will have to deal with bad tags, tags that aren&#039;t closed properly...&nbsp; Uppercase tags, lowercase tags... a bunch of stuff... good luck!</div>
    <div class="meta">Posted on 2011-04-18 16:02:41 by Gunner</div>
   </div>
   <div class="post" id="post-214320">
    <div class="subject"><a href="#post-214320">Re: How to download a web page to a .txt file</a></div>
    <div class="body">This is a start for you. &nbsp;It downloads a masm32 service pack page and translates it. &nbsp; I noticed it does not work with a dial up modem, only high speed. &nbsp;It does a kindergarten translation as it does not have word wrap.</div>
    <div class="attachments">Attachments:
     <ul>
      <li><a href="../../attachments/?id=3326" target="_blank">text.zip</a></li>
     </ul>
    </div>
    <div class="meta">Posted on 2011-04-20 13:03:38 by roaknog</div>
   </div>
  </div>
 </body>
</html>