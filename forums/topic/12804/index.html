<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8" />
  <title>Fast memcpy (block prefetch) - Forums - ASM Community</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" />
  <link rel="canonical" href="../?id=12804" />
     </head>
 <body>
  <div id="header">
   <h1><a href="../../../">ASM Community</a></h1>
  </div>
  <div id="content">
   <p class="breadcrumbs"><a href="../../../">Home</a> &raquo; <a href="../../">Forums</a> &raquo; <a href="../../board/?id=5">Algorithms &amp; Source Code</a> &raquo; <a href="../?id=12804">Fast memcpy (block prefetch)</a></p>
   <div class="post" id="post-99200">
    <div class="subject"><a href="#post-99200">Fast memcpy (block prefetch)</a></div>
    <div class="body">Howdy. <br />Just finished a large buffer memcpy (with size and alignment restrictions). It's optimized for Athlon XPs, and pretty fast - 2 to 3 times the throughput of VC7's code.<br />Any comments, thoughts, improvements? :)<br /><br />BTW, what would you all use for a 'general' version? I'm willing to assume PII+.<br /><pre><code><br />#define CHUNK_SIZE  4096<br />#define CHUNK_SHIFT 12<br /><br />/*<br /> * block prefetch memcpy for large, uncached arrays<br /> *<br /> * src and len must be multiples of CHUNK_SIZE.<br /> */<br />__declspec&#40;naked&#41; void memcpy_nt&#40;void* dst, void* src, int len&#41;<br />&#123;<br />__asm<br />&#123;<br />	push		esi<br /><br />	mov		edx, &#91;esp+4+4&#93;<br />	mov		esi, &#91;esp+4+8&#93;<br />	mov		ecx, &#91;esp+4+12&#93;<br />	shr		ecx, CHUNK_SHIFT			; # chunks<br />								; smaller than sub	ecx, CHUNK_SIZE below<br />main_loop&#58;<br /><br />; prefetch&#58; touch each cache line in chunk<br />; &#40;backwards to prevent hardware prefetches&#41;<br />	add		esi, CHUNK_SIZE<br />prefetch_loop&#58;<br />	mov		eax, &#91;esi-64&#93;<br />	mov		eax, &#91;esi-128&#93;<br />	sub		esi, 128<br />	test		esi, &#40;CHUNK_SIZE-1&#41;<br />	jnz		prefetch_loop<br /><br />; copy the chunk 64 bytes at a time<br />write_loop&#58;<br />	movq		mm0, &#91;esi&#93;<br />	movq		mm1, &#91;esi+8&#93;<br />	movq		mm2, &#91;esi+16&#93;<br />	movq		mm3, &#91;esi+24&#93;<br />	movq		mm4, &#91;esi+32&#93;<br />	movq		mm5, &#91;esi+40&#93;<br />	movq		mm6, &#91;esi+48&#93;<br />	movq		mm7, &#91;esi+56&#93;<br />	add		esi, 64<br />	test		esi, &#40;CHUNK_SIZE-1&#41;<br />	movntq		&#91;edx&#93;, mm0<br />	movntq		&#91;edx+8&#93;, mm1<br />	movntq		&#91;edx+16&#93;, mm2<br />	movntq		&#91;edx+24&#93;, mm3<br />	movntq		&#91;edx+32&#93;, mm4<br />	movntq		&#91;edx+40&#93;, mm5<br />	movntq		&#91;edx+48&#93;, mm6<br />	movntq		&#91;edx+56&#93;, mm7<br />	lea		edx, &#91;edx+64&#93;				; leave flags intact<br />	jnz		write_loop<br /><br />	dec		ecx<br />	jnz		main_loop<br /><br />	sfence<br />	emms<br /><br />	pop		esi<br />	ret<br />&#125;<br />&#125;</code></pre></div>
    <div class="meta">Posted on 2003-04-24 20:08:41 by Jan Wassenberg</div>
   </div>
   <div class="post" id="post-99245">
    <div class="subject"><a href="#post-99245">Fast memcpy (block prefetch)</a></div>
    <div class="body">Jan,<br /><br />It looks like a good technique for later processors, have you benchmarked it against the older &quot;rep movsd&quot; style memory copy functions to see how much faster it is. It would be a useful reference to people who are interested in this type of algo.<br /><br />Regards,<br /><br /><a href="mailto:hutch@movsd.com">hutch@movsd.com</a></div>
    <div class="meta">Posted on 2003-04-24 22:33:49 by hutch--</div>
   </div>
   <div class="post" id="post-99306">
    <div class="subject"><a href="#post-99306">Fast memcpy (block prefetch)</a></div>
    <div class="body">It's not really a fair contest - this code is makes good use of the cache, and blows movsd out of the water for large arrays:<br /><br />Measured: throughput . Test system: Athlon XP 1600+, 2/2/2 RAM.<br /><pre><code><br />size &#91;KB&#93;  128   160   192   256   320   384, 512, 1024, 2048<br />memcpy     1800  1100  300   350   350   350..400 &#40;varies&#41;<br />memcpy_nt  1450  1450  1450  1450  1350  950</code></pre><br /><br />(rep movsd performance is very similar to memcpy)<br /><br />Note to self: turn off fileserver before being despondent on seeing the newest benchmarks... :)<br /><br />/* edit: fixed table, movsd = memcpy */</div>
    <div class="meta">Posted on 2003-04-25 06:04:32 by Jan Wassenberg</div>
   </div>
   <div class="post" id="post-99361">
    <div class="subject"><a href="#post-99361">Fast memcpy (block prefetch)</a></div>
    <div class="body">Jan,<br /><br />Compliments on the testing, these are very good results and it shows that your algorithm is very fast.<br /><br />Thanks for posting the algo in here.<br /><br />Regards,<br /><br /><a href="mailto:hutch@movsd.com">hutch@movsd.com</a></div>
    <div class="meta">Posted on 2003-04-25 10:10:31 by hutch--</div>
   </div>
   <div class="post" id="post-99384">
    <div class="subject"><a href="#post-99384">Fast memcpy (block prefetch)</a></div>
    <div class="body">Thanks, and no problem.<br /><br />Can anyone comment on their general memcpy? This one is page granular, and only makes sense for large (&gt; 128 KB) arrays. I don't know whether I should go with FPU (8 byte alignment/increment is ok, and no emms needed), or MMX (supports non-temporal mov, but I don't know if that is beneficial here), or a simple unrolled loop (maximum compatibility).</div>
    <div class="meta">Posted on 2003-04-25 12:54:13 by Jan Wassenberg</div>
   </div>
   <div class="post" id="post-99387">
    <div class="subject"><a href="#post-99387">Fast memcpy (block prefetch)</a></div>
    <div class="body">Looks good to me.  I don't know that much about prefetching and even less about MMX instructions.<br /><br />I'd be interested to see a similar implementation of memmove() though.  Hint hint.  :grin:</div>
    <div class="meta">Posted on 2003-04-25 13:17:42 by iblis</div>
   </div>
   <div class="post" id="post-99428">
    <div class="subject"><a href="#post-99428">Fast memcpy (block prefetch)</a></div>
    <div class="body"><pre><code><br />MMX memcpy &#40;95 MB/s&#41;<br /><br />_asm &#123;<br />        mov esi, src<br />        mov edi, dest<br />        mov ecx, nbytes<br />        shr ecx, 6 // 64 bytes per iteration<br /><br />loop1&#58;<br />        movq mm1,  0&#91;ESI&#93; // Read in source data<br />        movq mm2,  8&#91;ESI&#93;<br />        movq mm3, 16&#91;ESI&#93;<br />        movq mm4, 24&#91;ESI&#93;<br />        movq mm5, 32&#91;ESI&#93;<br />        movq mm6, 40&#91;ESI&#93;<br />        movq mm7, 48&#91;ESI&#93;<br />        movq mm0, 56&#91;ESI&#93;<br /><br />        movq  0&#91;EDI&#93;, mm1 // Write to destination<br />        movq  8&#91;EDI&#93;, mm2<br />        movq 16&#91;EDI&#93;, mm3<br />        movq 24&#91;EDI&#93;, mm4<br />        movq 32&#91;EDI&#93;, mm5<br />        movq 40&#91;EDI&#93;, mm6<br />        movq 48&#91;EDI&#93;, mm7<br />        movq 56&#91;EDI&#93;, mm0<br /><br />        add esi, 64<br />        add edi, 64<br />        dec ecx<br />        jnz loop1<br /><br />        emms<br />&#125;<br /><br />MMX memcpy with non-temporal stores &#40;135 MB/s&#41;<br /><br />_asm &#123;<br />        mov esi, src<br />        mov edi, dest<br />        mov ecx, nbytes<br />        shr ecx, 6 // 64 bytes per iteration<br /><br />loop1&#58;<br />        movq mm1,  0&#91;ESI&#93; // Read in source data<br />        movq mm2,  8&#91;ESI&#93;<br />        movq mm3, 16&#91;ESI&#93;<br />        movq mm4, 24&#91;ESI&#93;<br />        movq mm5, 32&#91;ESI&#93;<br />        movq mm6, 40&#91;ESI&#93;<br />        movq mm7, 48&#91;ESI&#93;<br />        movq mm0, 56&#91;ESI&#93;<br /><br />        movntq  0&#91;EDI&#93;, mm1 // Non-temporal stores<br />        movntq  8&#91;EDI&#93;, mm2<br />        movntq 16&#91;EDI&#93;, mm3<br />        movntq 24&#91;EDI&#93;, mm4<br />        movntq 32&#91;EDI&#93;, mm5<br />        movntq 40&#91;EDI&#93;, mm6<br />        movntq 48&#91;EDI&#93;, mm7<br />        movntq 56&#91;EDI&#93;, mm0<br /><br />        add esi, 64<br />        add edi, 64<br />        dec ecx<br />        jnz loop1<br /><br />        emms<br />&#125;<br /><br />MMX memcpy with prefetch and non-temporal stores &#40;165 MB/s&#41;<br /><br />_asm &#123;<br />        mov esi, src<br />        mov edi, dest<br />        mov ecx, nbytes<br />        shr ecx, 6 // 64 bytes per iteration<br /><br />loop1&#58;<br />        prefetchnta 64&#91;ESI&#93; // Prefetch next loop, non-temporal<br />        prefetchnta 96&#91;ESI&#93;<br /><br />        movq mm1,  0&#91;ESI&#93; // Read in source data<br />        movq mm2,  8&#91;ESI&#93;<br />        movq mm3, 16&#91;ESI&#93;<br />        movq mm4, 24&#91;ESI&#93;<br />        movq mm5, 32&#91;ESI&#93;<br />        movq mm6, 40&#91;ESI&#93;<br />        movq mm7, 48&#91;ESI&#93;<br />        movq mm0, 56&#91;ESI&#93;<br /><br />        movntq  0&#91;EDI&#93;, mm1 // Non-temporal stores<br />        movntq  8&#91;EDI&#93;, mm2<br />        movntq 16&#91;EDI&#93;, mm3<br />        movntq 24&#91;EDI&#93;, mm4<br />        movntq 32&#91;EDI&#93;, mm5<br />        movntq 40&#91;EDI&#93;, mm6<br />        movntq 48&#91;EDI&#93;, mm7<br />        movntq 56&#91;EDI&#93;, mm0<br /><br />        add esi, 64<br />        add edi, 64<br />        dec ecx<br />        jnz loop1<br /><br />        emms<br />&#125;<br /><br /><br />MMX memcpy with prefetch, non-temporal stores, and streaming reads/ writes &#40;240 MB/s&#41;<br /><br />asm &#123;<br />        mov esi, src<br />        mov ecx, nbytes<br />        mov ebx, ecx<br />        shr ebx, 11 // 2048 bytes at a time<br />        mov edi, dest<br /><br />loop2k&#58; // Copy 2k into temporary buffer<br />        push edi<br />        mov edi, tbuf<br />        mov ecx, 2048<br />        shr ecx, 6<br /><br />loopMemToL1&#58;<br />        prefetchnta 64&#91;ESI&#93; // Prefetch next loop, non-temporal<br />        prefetchnta 96&#91;ESI&#93;<br /><br />        movq mm1,  0&#91;ESI&#93; // Read in source data<br />        movq mm2,  8&#91;ESI&#93;<br />        movq mm3, 16&#91;ESI&#93;<br />        movq mm4, 24&#91;ESI&#93;<br />        movq mm5, 32&#91;ESI&#93;<br />        movq mm6, 40&#91;ESI&#93;<br />        movq mm7, 48&#91;ESI&#93;<br />        movq mm0, 56&#91;ESI&#93;<br /><br />        movq  0&#91;EDI&#93;, mm1 // Store into L1<br />        movq  8&#91;EDI&#93;, mm2<br />        movq 16&#91;EDI&#93;, mm3<br />        movq 24&#91;EDI&#93;, mm4<br />        movq 32&#91;EDI&#93;, mm5<br />        movq 40&#91;EDI&#93;, mm6<br />        movq 48&#91;EDI&#93;, mm7<br />        movq 56&#91;EDI&#93;, mm0<br />        add esi, 64<br />        add edi, 64<br />        dec ecx<br />        jnz loopMemToL1<br /><br />        pop edi // Now copy from L1 to system memory<br />        push esi<br />        mov esi, tbuf<br />        mov ecx, 2048<br />        shr ecx, 6<br /><br />loopL1ToMem&#58;<br />        movq mm1, 0&#91;ESI&#93; // Read in source data from L1<br />        movq mm2, 8&#91;ESI&#93;<br />        movq mm3, 16&#91;ESI&#93;<br />        movq mm4, 24&#91;ESI&#93;<br />        movq mm5, 32&#91;ESI&#93;<br />        movq mm6, 40&#91;ESI&#93;<br />        movq mm7, 48&#91;ESI&#93;<br />        movq mm0, 56&#91;ESI&#93;<br /><br />        movntq 0&#91;EDI&#93;, mm1 // Non-temporal stores<br />        movntq 8&#91;EDI&#93;, mm2<br />        movntq 16&#91;EDI&#93;, mm3<br />        movntq 24&#91;EDI&#93;, mm4<br />        movntq 32&#91;EDI&#93;, mm5<br />        movntq 40&#91;EDI&#93;, mm6<br />        movntq 48&#91;EDI&#93;, mm7<br />        movntq 56&#91;EDI&#93;, mm0<br /><br />        add esi, 64<br />        add edi, 64<br />        dec ecx<br />        jnz loopL1ToMem<br /><br />        pop esi // Do next 2k block<br />        dec ebx<br />        jnz loop2k<br />&#125;</code></pre></div>
    <div class="meta">Posted on 2003-04-25 18:16:22 by lingo12</div>
   </div>
   <div class="post" id="post-99433">
    <div class="subject"><a href="#post-99433">Fast memcpy (block prefetch)</a></div>
    <div class="body">Random thoughts:<br /><br />1.  Jan, doesn't Athlon support <strong>prefetch</strong> family of instructions?<br /><br />2.  I was in a flame-war like situation with this topic about 2 years ago elsewhere.  I was more or less skeptical about the efficiency bound of MMX/SSE enhanced memcpy/memmove, and that invited whole lot of flame throwers.  But, I'm not convinced yet.   How large does the third arg to memcpy() have to be in order for this routine to be dominantly faster?<br /><br />3.  I tried a similar thing after the forementioned flamewar.  My test showed that <strong>movntq</strong> and <strong>sfence</strong> cost more than simple <strong>movq</strong> on my Pentium III.  Since then, I don't use <strong>movntq</strong> in my code.  Is <strong>movntq</strong> much better on Athlon or Pentium 4?<br /><br />4.  Maybe moderators want to set up a subforum about memcpy/memmove/memset/BitBlt/strlen/strcpy.   This topic pops up in this board frequently.  I think that is natural because they are a focal point of optimization.   What about directing all those efforts to one subforum so that people do not re-invent wheels over and over again?</div>
    <div class="meta">Posted on 2003-04-25 19:25:37 by Starless</div>
   </div>
   <div class="post" id="post-99460">
    <div class="subject"><a href="#post-99460">Fast memcpy (block prefetch)</a></div>
    <div class="body">Lingo,<br /><br />Great stuff. :alright: <br /><br />Regards,<br /><br /><a href="mailto:hutch@movsd.com">hutch@movsd.com</a></div>
    <div class="meta">Posted on 2003-04-25 22:25:16 by hutch--</div>
   </div>
   <div class="post" id="post-99519">
    <div class="subject"><a href="#post-99519">Fast memcpy (block prefetch)</a></div>
    <div class="body">Thanks for all replies.<br /><br />Iblis:<br />&gt; I'd be interested to see a similar implementation of memmove() though.<br />On first glance, looks difficult ;) Will give this some thought...<br /><br />lingo12:<br />Looks like our methods are similar. Your last code (modified a tiny bit for VC7?s masm) gets the following numbers in my benchmark:<br />128, 160, 192, 256: 1340<br />320: 980..1020<br />384, 512, 1024, 2048: 580<br />Why are you copying twice? To prefetch (load into cache), all you need to do is touch one cache line (one memory access).<br /><br />Starless:<br />&gt; 1. Jan, doesn't Athlon support prefetch family of instructions?<br />Yes. Problem with prefetch is they can be ignored, and only 3 can be in flight at any time (but I want to start reading 4 KB).<br /><br />&gt;2. I was in a flame-war like situation with this topic about 2 years ago elsewhere. I was more or less skeptical about the efficiency bound of MMX/SSE enhanced memcpy/memmove, and that invited whole lot of flame throwers. But, I'm not convinced yet. How large does the third arg to memcpy() have to be in order for this routine to be dominantly faster?&lt;<br />Convince yourself ? check the numbers :) This method is significantly faster when the arrays don?t fit in cache (transfer size &gt; 128 KB).<br /><br />&gt;3. I tried a similar thing after the forementioned flamewar. My test showed that movntq and sfence cost more than simple movq on my Pentium III. Since then, I don't use movntq in my code. Is movntq much better on Athlon or Pentium 4?&lt;<br />movntq is rated at 3 clocks (Athlon XP) ? I don?t see any problems. What transfer sizes did you test? Were the buffers already in cache?<br /><br />&gt;4. Maybe moderators want to set up a subforum about memcpy/memmove/memset/BitBlt/strlen/ strcpy. This topic pops up in this board frequently. I think that is natural because they are a focal point of optimization. What about directing all those efforts to one subforum so that people do not re-invent wheels over and over again?&lt;<br />Good idea, I?m all for it! :)</div>
    <div class="meta">Posted on 2003-04-26 09:57:26 by Jan Wassenberg</div>
   </div>
   <div class="post" id="post-99603">
    <div class="subject"><a href="#post-99603">Fast memcpy (block prefetch)</a></div>
    <div class="body"><div class="quote"><br />4.  Maybe moderators want to set up a subforum about memcpy/memmove/memset/BitBlt/strlen/strcpy.   This topic pops up in this board frequently.  I think that is natural because they are a focal point of optimization.   What about directing all those efforts to one subforum so that people do not re-invent wheels over and over again? </div><br /><br />Just pick suitable thread names or ask a moderator to change it afterwards and learn to use the search engine ;)</div>
    <div class="meta">Posted on 2003-04-26 20:31:13 by bazik</div>
   </div>
   <div class="post" id="post-99625">
    <div class="subject"><a href="#post-99625">Fast memcpy (block prefetch)</a></div>
    <div class="body">Jan,<br /><br />What is probably a good idea is your original offer of designing a block memory copy routine that does not have to be run on a PIII or later as many people are still using older boxes and will be for a long time to come.<br /><br />The pretouching technique that you used looks like it will work on older stuff without assuming the PIII PV prefetch instructions so it would be very useful there.<br /><br />It is very easy to translate the code you have posted into masm format and it would be able to be used by a far larger number of people.<br /><br />Regards,<br /><br /><a href="mailto:hutch@movsd.com">hutch@movsd.com</a></div>
    <div class="meta">Posted on 2003-04-27 00:17:40 by hutch--</div>
   </div>
   <div class="post" id="post-99647">
    <div class="subject"><a href="#post-99647">Fast memcpy (block prefetch)</a></div>
    <div class="body">For wheel inventors:<br />&quot;Using Block Prefetch for Optimized Memory Performance&quot;<br /><a target="_blank" href="http://cdrom.amd.com/devconn/events/AMD_block_prefetch_paper.pdf">http://cdrom.amd.com/devconn/events/AMD_block_prefetch_paper.pdf</a><br />&quot;AMD Athlon Processor x86 Code Optimization Guide TM&quot;<br />22007.pdf<br />&quot;Intel? Pentium? 4 Processor Optimization&quot;<br />24896602.pdf</div>
    <div class="meta">Posted on 2003-04-27 03:51:44 by Nexo</div>
   </div>
   <div class="post" id="post-99654">
    <div class="subject"><a href="#post-99654">Fast memcpy (block prefetch)</a></div>
    <div class="body">Nexo,<br /><br />Thanks, its a good article.<br /><br />Regards,<br /><br /><a href="mailto:hutch@movsd.com">hutch@movsd.com</a></div>
    <div class="meta">Posted on 2003-04-27 04:46:09 by hutch--</div>
   </div>
   <div class="post" id="post-99820">
    <div class="subject"><a href="#post-99820">Fast memcpy (block prefetch)</a></div>
    <div class="body">Hutch: the above code is in masm format, even if I've avoided the red tape :grin:<br /><br />Nexo: yes, I'm aware of the block prefetch paper (hence the name ;)). This code is smaller+faster.</div>
    <div class="meta">Posted on 2003-04-28 09:17:41 by Jan Wassenberg</div>
   </div>
   <div class="post" id="post-99912">
    <div class="subject"><a href="#post-99912">Fast memcpy (block prefetch)</a></div>
    <div class="body">Jan,<br /><br />You will have to forgive me but at the moment I onlt have about half a brain left and its working in parsing design, not high speed block copy.<br /><br />When you offered to develop a version that would work on a PII, I was interested because many people don't have the latest whizz bang hardware and your pretouching design looked like it could be used to get good speed increases on older machines over the standard REP MOVSD style of code.<br /><br />If you do have the time to put together a version that would work on an old timer, I am sure it would be appreciated by many people who don't own late model hardware.<br /><br />Regards,<br /><br /><a href="mailto:hutch@movsd.com">hutch@movsd.com</a></div>
    <div class="meta">Posted on 2003-04-28 23:34:02 by hutch--</div>
   </div>
   <div class="post" id="post-101262">
    <div class="subject"><a href="#post-101262">movNTq is great - PIII routines</a></div>
    <div class="body">Starless, movNTq is great under certain circumstances, though I was skeptical I could use it one day.<br /><br />That day came... Into my code I first init a huge Transposition Table (64 bytes * 1 million items).<br />I reinit this TT several times in my program : I zeroe a few bytes for each item before my TT can be reused.<br /><br />I simply changed movq ,mm0 by a movNTq ,mm0... copy takes now 0.05 instead of 0.5 s, on my PIII 650 MHz, 256 KB L2, I could hardly believe it !<br /><br />So when it is huge and out of cache, do not pollute it...<br /><br />Thx for the code, Jan&amp;lingo12</div>
    <div class="meta">Posted on 2003-05-05 06:00:09 by valy</div>
   </div>
   <div class="post" id="post-101480">
    <div class="subject"><a href="#post-101480">Fast memcpy (block prefetch)</a></div>
    <div class="body">Sorry for the late reply; my internet connection was down :(<br /><br />hutch--: my wording was probably poor. I was asking for advice on the general version, which should work on older (k6, PII) CPUs and assume less.<br /><br />Yeah, I suppose block prefetching is applicable to older processors.<br /><br />&gt; If you do have the time to put together a version that would work on an old timer, I am sure it would be appreciated by many people who don't own late model hardware. &lt;<br />Working on it, very busy at the moment.<br /><br />valy: hehe, nice :)<br />Glad to.</div>
    <div class="meta">Posted on 2003-05-06 05:50:30 by Jan Wassenberg</div>
   </div>
  </div>
 </body>
</html>