<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8" />
  <title>Processing Vectors with SSE - Forums - ASM Community</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" />
  <link rel="canonical" href="../?id=14138" />
     </head>
 <body>
  <div id="header">
   <h1><a href="../../../">ASM Community</a></h1>
  </div>
  <div id="content">
   <p class="breadcrumbs"><a href="../../../">Home</a> &raquo; <a href="../../">Forums</a> &raquo; <a href="../../board/?id=5">Algorithms &amp; Source Code</a> &raquo; <a href="../?id=14138">Processing Vectors with SSE</a></p>
   <div class="post" id="post-109250">
    <div class="subject"><a href="#post-109250">Processing Vectors with SSE</a></div>
    <div class="body">Hi guys, <br />I was converting the following C function to some Asm SSE code. You might be interested in it, I know I'd be interested in any suggestions to improve it. Heres the C function,<br /><pre><code>double L2_norm&#40;vec,dim&#41;<br />     double *vec;<br />     short dim;<br />&#123;<br />    int i;<br />    double t_sum=0.0;<br /><br />    for &#40;i=0; i&lt;dim; i++&#41;<br />      t_sum += vec&#91;i&#93;*vec&#91;i&#93;;<br /><br />    return&#40;sqrt&#40;t_sum&#41;&#41;;<br />&#125;</code></pre><br />First I wrote a literal translation<br /><pre><code>proc L2_NormSlow,pV,sV<br />enter<br />	mov edx,&#91;pV&#93;<br />	mov ecx,&#91;sV&#93;<br />	add edx,&#91;sV&#93;<br />	neg ecx<br />	<br />	xorps xmm0,xmm0<br />	.sseLp&#58;	movss xmm1,&#91;edx+ecx&#93;<br />		mulss xmm1,xmm1<br />		addss xmm0,xmm1<br />	add ecx,4<br />	js .sseLp<br />	<br />	sqrtss xmm0,xmm0	<br />return</code></pre><br />Ugly I know but I really just wanted something that worked so I could test my answers. Then I worte this much longer version,<br /><span style="font-size:9px><pre><code>proc L2_Norm,pV,sV<br />enter<br />	mov ecx,&#91;sV&#93;<br />	mov edx,&#91;pV&#93;<br />	<br />	xorps xmm4,xmm4<br />	add edx,ecx<br />	xorps xmm0,xmm0<br />	neg ecx<br />	xorps xmm1,xmm1	<br />	<br />	add ecx,32<br />	jg .nops<br />	<br />	.psLp&#58;	movaps xmm2,&#91;edx+ecx-32&#93;<br />		movaps xmm3,&#91;edx+ecx-16&#93;<br />		<br />		mulps xmm2,xmm2<br />		mulps xmm3,xmm3<br />		<br />		addps xmm0,xmm2<br />		addps xmm1,xmm3<br />	add ecx,32<br />	jng .psLp<br />	<br />	movlhps xmm2,xmm0<br />	movlhps xmm3,xmm1<br />	<br />	addps xmm2,xmm0<br />	addps xmm3,xmm1<br />	addps xmm2,xmm3<br />	<br />	shufps xmm3,xmm2,10101010b<br />	addps xmm3,xmm2			&#91;COLOR=green&#93;; &lt;== UGLY!&#91;/COLOR&#93;<br />	shufps xmm3,xmm3,11111111b<br />	<br />	movaps xmm4,xmm3<br />	<br />.nops&#58;	sub ecx,32<br />	jz .exit<br />		<br />	xorps xmm0,xmm0<br />	xorps xmm1,xmm1<br />	<br />	add ecx,8<br />	jg .noss<br />	<br />	.ssLp&#58;	movss xmm2,pd&#91;edx+ecx-8&#93;<br />		movss xmm3,pd&#91;edx+ecx-4&#93;<br />		<br />		mulss xmm2,xmm2<br />		mulss xmm3,xmm3<br />		<br />		addss xmm0,xmm2<br />		addss xmm1,xmm3	<br />	add ecx,8<br />	jng .ssLp	<br /><br />	addss xmm4,xmm0	<br />	addss xmm4,xmm1<br />	<br />.noss&#58;	sub ecx,8<br />	jz .exit	<br />	<br />	movss xmm0,pd&#91;edx-4&#93;<br />	mulss xmm0,xmm0			&#91;COLOR=green&#93;; &lt;== UGLY!&#91;/COLOR&#93;<br />	addss xmm4,xmm0<br /><br />.exit&#58;	sqrtss xmm0,xmm4		<br />return</code></pre></span><br />It has two loops, the first process blocks of 8 values, the second processes blocks of 2 and the case of a final value left over is accounted for.<br /><br />The actual SSE code isn't really complicated, there are two noted ugly bits where I imagine stalls will happen, maybe there are more?<br /><br />The bit I'm most intrested in is the general loop code which can be applied to different processing of many vectors, that code I seperated here, it'd be interesting to see how fast that can be made. (Though heavy calculations would maybe make improvements here irrevelant)<br /><span style="font-size:9px><pre><code>proc VectorLoop,pV,sV<br />enter<br />	mov ecx,&#91;sV&#93;<br />	mov edx,&#91;pV&#93;<br />	<br />	add edx,ecx<br />	neg ecx<br />	<br />	&#91;COLOR=green&#93;; Initial processing&#91;/COLOR&#93;<br />	<br />	add ecx,32<br />	jg .nops<br />	<br />	&#91;COLOR=green&#93;; Pre 8 value loop processing&#91;/COLOR&#93;<br />	<br />	.psLp&#58;	&#91;COLOR=green&#93;; 8 value loop&#91;/COLOR&#93;<br />	<br />		&#91;COLOR=green&#93;; 1st 4 -&gt; &#91;edx+ecx-32&#93;&#91;/COLOR&#93;<br />		&#91;COLOR=green&#93;; 2nd 4 -&gt; &#91;edx+ecx-16&#93;&#91;/COLOR&#93;<br />	<br />	add ecx,32<br />	jng .psLp<br />	<br />	&#91;COLOR=green&#93;; Post 8 value loop processing&#91;/COLOR&#93;<br />	<br />.nops&#58;	sub ecx,32<br />	jz .exit<br />		<br />	add ecx,8<br />	jg .noss<br />	<br />	&#91;COLOR=green&#93;; Pre 2 value loop processing&#91;/COLOR&#93;<br />	<br />	.ssLp&#58;	&#91;COLOR=green&#93;; 2 value loop&#91;/COLOR&#93;<br />	<br />		&#91;COLOR=green&#93;; 1st -&gt; &#91;edx+ecx-8&#93;&#91;/COLOR&#93;<br />		&#91;COLOR=green&#93;; 2nd -&gt; &#91;edx+ecx-4&#93;&#91;/COLOR&#93;<br />	<br />	add ecx,8<br />	jng .ssLp	<br /><br />	&#91;COLOR=green&#93;; Post 2 value loop processing&#91;/COLOR&#93;<br />	<br />.noss&#58;	sub ecx,8<br />	jz .exit	<br />	<br />	&#91;COLOR=green&#93;; Final value processing&#91;/COLOR&#93;<br />	<br />	&#91;COLOR=green&#93;; value -&gt; &#91;edx-4&#93;&#91;/COLOR&#93;<br /><br />.exit&#58;	&#91;COLOR=green&#93;; Final processing&#91;/COLOR&#93;		<br />return</code></pre></span><br />For large (approx 128mb) vectors the longer version runs in about 75% the time of the shorter. For small (approx 1kb) vectors the longer version runs in &lt; 25% the time of the shorter. Any opinions?</div>
    <div class="meta">Posted on 2003-07-04 12:25:07 by Eóin</div>
   </div>
   <div class="post" id="post-109582">
    <div class="subject"><a href="#post-109582">Processing Vectors with SSE</a></div>
    <div class="body"><strong>E?in</strong>, might not gain much more speed, but I'd unroll the loop until all instruction latencies are hidden within other instructions.<br /><br /><br /><br /><pre><code><br />.psLp&#58;<br />	mulps xmm4,xmm4<br />	mulps xmm5,xmm5<br /><br />	addps xmm0,xmm2<br />	addps xmm1,xmm3<br /><br />	movaps xmm2,&#91;edx+ecx-16*4&#93;<br />	movaps xmm3,&#91;edx+ecx-16*3&#93;<br /><br />	addps xmm0,xmm4<br />	addps xmm1,xmm5<br /><br />	movaps xmm4,&#91;edx+ecx-16*2&#93;<br />	movaps xmm5,&#91;edx+ecx-16*1&#93;<br /><br />	mulps xmm2,xmm2<br />	mulps xmm3,xmm3<br /><br />	add ecx,16*4<br />	jng .psLp</code></pre>...I'm just guessing from memory.  Sorry, hope you get the idea?  Look at the latencies for each instruction - this will be a greater boost for cached data.  Check to see if it's already memory bound on 128MB's - if so, you've reached the limit on your machine. :)</div>
    <div class="meta">Posted on 2003-07-07 14:19:03 by bitRAKE</div>
   </div>
   <div class="post" id="post-109622">
    <div class="subject"><a href="#post-109622">Processing Vectors with SSE</a></div>
    <div class="body">E?in,<br /><br />Now that you use SSE, you can safely assume that <strong>prefetch</strong> family of instructions are available.  That may help speeding up in a (relatively) long loop.  It seems to me that something longer than 128 bytes may benefit from <strong>prefetch</strong> instructions.  (But, this is purely from my experience and not an experiment result.  The threshold may be lower or higher if you experiment rigorously.)<br /><br />For short vectors (like remaining elements after the main loop in your code), it may be faster to use an unrolled loop of FPU instructions.  For an example of FPU version of l_2 norm, see <a target="_blank" href="http://www.asmcommunity.net/board/showthread.php?threadid=5793">this post</a>.<br /><br />Minor points:<br />1.  The current version may overflow even if the final value is representable in single precision.  (And, this is a part of the reason why I'm not a big fan of SSE for numerical analysis.)  You know, the usual trick is to divide each element by the maximum element and then accumulate.  If memory is much slower than the division operation, the way that BLAS dnrm2 is implemented may be faster.<br /><br />2.  I suppose that <strong>sV</strong> is not the same as <strong>dim</strong> in the C version, otherwise you need <strong>shl</strong> at the beginning of the function.</div>
    <div class="meta">Posted on 2003-07-07 18:51:44 by Starless</div>
   </div>
   <div class="post" id="post-109697">
    <div class="subject"><a href="#post-109697">Processing Vectors with SSE</a></div>
    <div class="body">bitRAKE, I think I follow what you're saying. That example you give certainly is faster, down to about 15% &amp; 65% for large and small respectivly. I'll try and get myself a list of those latencies. Thanks,<br /><br />Starless, I don't really understand the prefetch instruction, I seem to get an illegal instrucion.</div>
    <div class="meta">Posted on 2003-07-08 17:29:37 by Eóin</div>
   </div>
  </div>
 </body>
</html>