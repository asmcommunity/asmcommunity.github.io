<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8" />
  <title>Fast Dot Product - Forums - ASM Community</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" />
  <link rel="canonical" href="../?id=30153" />
    <link rel="next" href="../?id=30153&amp;page=2" /> </head>
 <body>
  <div id="header">
   <h1><a href="../../../">ASM Community</a></h1>
  </div>
  <div id="content">
   <p class="breadcrumbs"><a href="../../../">Home</a> &raquo; <a href="../../">Forums</a> &raquo; <a href="../../board/?id=3">MAIN</a> &raquo; <a href="../?id=30153">Fast Dot Product</a></p>
<form class="pagination" action="../" method="get"><a href="../?id=30153&amp;page=1" style="visibility:hidden;">&laquo;</a><a href="../?id=30153&amp;page=0" style="visibility:hidden;">&lt;</a><input type="hidden" name="id" value="30153" /><input type="number" name="page" min="1" max="2" step="1" value="1" onchange="this.form.submit();" /><a href="../?id=30153&amp;page=2">&gt;</a><a href="../?id=30153&amp;page=2">&raquo;</a></form>   <div class="post" id="post-212646">
    <div class="subject"><a href="#post-212646">Fast Dot Product</a></div>
    <div class="body">The dot product or scalar product or inner product of 2 vectors of the dimension n is defined as:<br /><br />&lt; x, y &gt; = x[0]*y[0] + x[1]*y[1] + ... + x*y<br /><br />The inner product is a common and often used procedure in the BLAS (Basic Linear Algebra Subprograms). It’s a de facto application programming interface standard for publishing libraries to perform basic linear algebra operations such as vector and matrix multiplication. They were first published in 1979, and are used to build larger packages. They are heavily used in high-performance computing.<br /><br />Let’s assume that every array element is a Single Precision (float) value; both arrays are properly aligned by 16. Every array contains 256 elements, so caching shouldn&#039;t be a question. I need a fast implementation for that operation. Who can help?<br /><br />Gunther</div>
    <div class="meta">Posted on 2010-08-13 12:58:26 by Gunther</div>
   </div>
   <div class="post" id="post-212647">
    <div class="subject"><a href="#post-212647">Re: Fast Dot Product</a></div>
    <div class="body">You didn&#039;t specify what, where and with what. I&#039;m assuming windows and x86 or x86_64 asm module. Your post looks like it has been copy-pasted.<br /><br />Anyway something like this should do it:<br /><pre><code>	; use jwasm<br />if @WordSize ne 8<br />.686<br />.xmm<br />.model flat,c<br />endif<br />option casemap:none<br /><br />.code<br /><br />	;// extern &quot;C&quot; float fastdotp256(float *v1,float *v2);<br />	public _fastdotp256<br />_fastdotp256:<br />	if @WordSize eq 4<br />	mov ecx,<br />	mov edx,<br />	v1 equ &lt;ecx&gt;<br />	v2 equ &lt;edx&gt;<br />	else<br />	v1 equ &lt;rcx&gt;<br />	v2 equ &lt;rdx&gt;<br />	endif<br />	xorps xmm0,xmm0<br />	i = 0<br />	repeat 256/4<br />		movaps xmm1,<br />		mulps xmm1,<br />		addps xmm0,xmm1<br />		i = i + 1<br />	endm<br />	movhlps xmm1,xmm0<br />	addps xmm1,xmm0<br />	movq xmm0,xmm1<br />	psrlq xmm0,32<br />	addss xmm0,xmm1<br />	movd eax,xmm0<br />	ret<br /><br />end</code></pre><br /><br />you could go faster with dpps (SSE4.1)<br /></div>
    <div class="meta">Posted on 2010-08-13 19:34:19 by drizz</div>
   </div>
   <div class="post" id="post-212652">
    <div class="subject"><a href="#post-212652">Re: Fast Dot Product</a></div>
    <div class="body">Hallo drizz,<br /><br />thank you for that fast reply.<br /><br /><div class="quote">Your post looks like it has been copy-pasted.</div><br /><br />No, it isn&#039;t.<br /><br /><div class="quote">You didn&#039;t specify what, where and with what.</div><br /><br />That&#039;s right. It&#039;s an application for the Fractal Image Compression. The program works under 32-bit UNIX and Windows and is written in C++. After a serious analysis with code walk-through and profiling, I&#039;ve got the following result: The bottlenecks are exactly 6 procedures. For example, having an image of 256 x 256 pixels, those functions are called over 30 million times. The next question is: What exactly is the purpose of those 6 functions? They are computing several statistical parameters, like the arithmetic mean, the variance or the co-variance, which are needed for the so called linear regression. In other words: hard number crunching.<br /><br />At the moment, I&#039;m writing a test bed (C++ and Assembly Language), to show what I&#039;ve found until now. <br /><br /><div class="quote">Anyway something like this should do it:</div><br /><br />Good SSE2 code, your ideas are welcome.<br /><br /><div class="quote">you could go faster with dpps (SSE4.1)</div><br /><br />Sure, but SSE4.1 isn&#039;t very wide spread. Furthermore, would it work with AMD?<br /><br />Gunther<br /> <br /><br /><br /><br /> </div>
    <div class="meta">Posted on 2010-08-13 21:47:22 by Gunther</div>
   </div>
   <div class="post" id="post-212661">
    <div class="subject"><a href="#post-212661">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote">Sure, but SSE4.1 isn&#039;t very wide spread. Furthermore, would it work with AMD?</div><br />AMD&#039;s CPUS have their own SSE4a (IMHO very useless, esp. when compared with 4.1&#039;s MPSADBW and dot product).</div>
    <div class="meta">Posted on 2010-08-14 09:02:47 by ti_mo_n</div>
   </div>
   <div class="post" id="post-212662">
    <div class="subject"><a href="#post-212662">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote"><br /><div class="quote">you could go faster with dpps (SSE4.1)</div><br />Sure, but SSE4.1 isn&#039;t very wide spread. Furthermore, would it work with AMD?<br /></div>IIRC maybe next year ;), there&#039;s always cpuid and different code paths. <br /><br /><div class="quote"><br />At the moment, I&#039;m writing a test bed (C++ and Assembly Language), to show what I&#039;ve found until now. <br /></div><br />Posting that testbed and c++ code for those 6 functions is the way to go. Maybe some optimizations can be done on algorithmic/source level. Maybe some parts don&#039;t really need to be floats? What&#039;s the image format?<br /><br /><div class="quote"><br /><div class="quote">Anyway something like this should do it:</div><br /><br />Good SSE2 code, your ideas are welcome.<br /></div><br />You can&#039;t really out-optimize mul + add. Using intrinsics and or optimization options (loop unrolling, architecture) you can produce the same code without asm I&#039;m sure.<br /><br /></div>
    <div class="meta">Posted on 2010-08-14 09:14:07 by drizz</div>
   </div>
   <div class="post" id="post-212664">
    <div class="subject"><a href="#post-212664">Re: Fast Dot Product</a></div>
    <div class="body"><br /><div class="quote">Posting that testbed and c++ code for those 6 functions is the way to go. Maybe some optimizations can be done on algorithmic/source level.</div><br /><br />Sure. The only crucial point is the dot product. But how can I attach the files to a forum message? It seems to me that&#039;s not enabled for my account. <br /><br /><div class="quote">Maybe some parts don&#039;t really need to be floats? What&#039;s the image format?</div><br /><br />The Encoder needs TGA images and the Decoder&#039;s output is a TGA file, too. But that isn&#039;t the point. Internally it&#039;s a bad idea to operate with the RGB color model. It&#039;s better to use YCbCr; furthermore the entire algorithm makes it necessary to shrink the original image into smaller parts. Therefore one has to compute the arithmetic mean of several pixels; the result is a float or double. I&#039;ve tested the rounding to integer data types; it works, but you have to pay a price: the image quality isn&#039;t so good. At the present time, floats are the only way to go.<br /><br /><div class="quote">Using intrinsics and or optimization options (loop unrolling, architecture) you can produce the same code without asm I&#039;m sure.</div><br /><br />I&#039;m not sure. But let&#039;s discuss that point at the basis of my test program. <br /><br />Gunther<br /><br /><br /></div>
    <div class="meta">Posted on 2010-08-14 10:25:41 by Gunther</div>
   </div>
   <div class="post" id="post-212665">
    <div class="subject"><a href="#post-212665">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote"><div class="quote">Using intrinsics and or optimization options (loop unrolling, architecture) you can produce the same code without asm I&#039;m sure.</div><br /><br />I&#039;m not sure. But let&#039;s discuss that point at the basis of my test program. </div><br /><br />gcc 3.4.5 mingw<br /><br /><em>(I&#039;m not overly familiar with all of gcc&#039;s optimization options)</em><br /><br />gcc -O3 -w -c -march=pentium4 -mfpmath=sse -msse2 -mtune=pentium4 -ffast-math -fno-inline-functions -funroll-loops -fomit-frame-pointer <br /><br /><pre><code>float dotp256_intrin(float *v1, float *v2)<br />{<br />	__m128 xmm1, *xv1=(__m128 *)v1, *xv2=(__m128 *)v2;<br />	__m128 xmm0 = {0,0,0,0};<br />	<br />	for (int i = 0; i &lt; 256/4; i++)<br />	{<br />		xmm1 = _mm_mul_ps(xv1<em>,xv2<em>);<br />		xmm0 = _mm_add_ps(xmm0,xmm1);<br />	}<br /><br />	xmm1 = _mm_movehl_ps(xmm1,xmm0);<br />	xmm1 = _mm_add_ps(xmm1,xmm0);<br />	xmm0 = xmm1;<br />	xmm0 = (__m128)_mm_srli_epi64((__m128i)xmm0,32);<br />	xmm0 = _mm_add_ss(xmm0,xmm1);<br />	<br />	float result;<br />	_mm_store_ss( &amp;result, xmm0);<br />	return result;<br />}</code></pre><br /><br /><pre><code>CPU Disasm<br />Address &nbsp; &nbsp;Command &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Comments<br />$ ==&gt; &nbsp; &nbsp; &nbsp;push ebx<br />$+1 &nbsp; &nbsp; &nbsp; &nbsp;xorps xmm2,xmm2<br />$+4 &nbsp; &nbsp; &nbsp; &nbsp;xor eax,eax<br />$+6 &nbsp; &nbsp; &nbsp; &nbsp;sub esp,4<br />$+9 &nbsp; &nbsp; &nbsp; &nbsp;mov ebx,3F<br />$+E &nbsp; &nbsp; &nbsp; &nbsp;mov ecx,<br />$+12 &nbsp; &nbsp; &nbsp; mov edx,<br />$+16 &nbsp; &nbsp; &nbsp; /movaps xmm7,<br />$+1A &nbsp; &nbsp; &nbsp; |mulps xmm7,<br />$+1E &nbsp; &nbsp; &nbsp; |addps xmm2,xmm7<br />$+21 &nbsp; &nbsp; &nbsp; |movaps xmm6,<br />$+26 &nbsp; &nbsp; &nbsp; |mulps xmm6,<br />$+2B &nbsp; &nbsp; &nbsp; |movaps xmm5,<br />$+30 &nbsp; &nbsp; &nbsp; |movaps xmm4,<br />$+35 &nbsp; &nbsp; &nbsp; |mulps xmm5,<br />$+3A &nbsp; &nbsp; &nbsp; |addps xmm2,xmm6<br />$+3D &nbsp; &nbsp; &nbsp; |mulps xmm4,<br />$+42 &nbsp; &nbsp; &nbsp; |movaps xmm3,<br />$+47 &nbsp; &nbsp; &nbsp; |addps xmm2,xmm5<br />$+4A &nbsp; &nbsp; &nbsp; |movaps xmm1,<br />$+4F &nbsp; &nbsp; &nbsp; |mulps xmm3,<br />$+54 &nbsp; &nbsp; &nbsp; |addps xmm2,xmm4<br />$+57 &nbsp; &nbsp; &nbsp; |mulps xmm1,<br />$+5C &nbsp; &nbsp; &nbsp; |movaps xmm0,<br />$+61 &nbsp; &nbsp; &nbsp; |addps xmm2,xmm3<br />$+64 &nbsp; &nbsp; &nbsp; |addps xmm2,xmm1<br />$+67 &nbsp; &nbsp; &nbsp; |mulps xmm0,<br />$+6C &nbsp; &nbsp; &nbsp; |movaps xmm1,<br />$+71 &nbsp; &nbsp; &nbsp; |mulps xmm1,<br />$+76 &nbsp; &nbsp; &nbsp; |addps xmm2,xmm0<br />$+79 &nbsp; &nbsp; &nbsp; |sub eax,-80<br />$+7C &nbsp; &nbsp; &nbsp; |sub ebx,8<br />$+7F &nbsp; &nbsp; &nbsp; |addps xmm2,xmm1<br />$+82 &nbsp; &nbsp; &nbsp; \jns short 004014FE<br />$+84 &nbsp; &nbsp; &nbsp; movhlps xmm1,xmm2<br />$+87 &nbsp; &nbsp; &nbsp; addps xmm1,xmm2<br />$+8A &nbsp; &nbsp; &nbsp; movdqa xmm2,xmm1<br />$+8E &nbsp; &nbsp; &nbsp; psrlq xmm2,20<br />$+93 &nbsp; &nbsp; &nbsp; addss xmm2,xmm1<br />$+97 &nbsp; &nbsp; &nbsp; movss ,xmm2<br />$+9C &nbsp; &nbsp; &nbsp; fld dword ptr <br />$+9F &nbsp; &nbsp; &nbsp; add esp,4<br />$+A2 &nbsp; &nbsp; &nbsp; pop ebx<br />$+A3 &nbsp; &nbsp; &nbsp; retn<br /></code></pre><br /></div>
    <div class="meta">Posted on 2010-08-14 12:36:02 by drizz</div>
   </div>
   <div class="post" id="post-212704">
    <div class="subject"><a href="#post-212704">Re: Fast Dot Product</a></div>
    <div class="body">Hallo drizz,<br /><br /><div class="quote">(I&#039;m not overly familiar with all of gcc&#039;s optimization options)</div><br /><br />Never mind, I can figure out that point. Thank you for your intrinsic code. Until now I gave intrinsics a wide berth, but it seems that&#039;s a good alternative, especially with the goal, to migrate software to another operating system. Do you know any descriptions for the hole bunch of gcc intrinsics?<br /><br />Anyway, I&#039;ve included your code in my test bed. My goal was to write several variants for the dot product, not only for that special case of a vector length of 256. The main program defines 2 floating point vectors (aligned by 16), calls the 6 different functions 5 million times and measures the time. It&#039;s written in C++ and with gcc inline assembler. It compiles with gcc 3.4.5 and better. I made timings under WinXP and Linux (both 32 bit).<br /><br />The intresting thing is, that your intrinsic code always compete with a simple SSE2 implementation (4 array elements per loop cycle). But more sophisticated SSE2 implementations are a lot faster. I could publish the timings here, but that doesn&#039;t make sense without the complete source code, so that anyone interested can test it. Is it possible to send the source code via mail to you? I&#039;m sure, there is room for improvement. The trick is, that my forum account doesnt allow attachments.<br /><br />Gunther<br />&nbsp;  </div>
    <div class="meta">Posted on 2010-08-15 13:19:36 by Gunther</div>
   </div>
   <div class="post" id="post-212705">
    <div class="subject"><a href="#post-212705">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote"><br />Never mind, I can figure out that point. Thank you for your intrinsic code. Until now I gave intrinsics a wide berth, but it seems that&#039;s a good alternative, especially with the goal, to migrate software to another operating system. Do you know any descriptions for the hole bunch of gcc intrinsics?</div> There&#039;s a prototype for intrinsic under every instruction in the intel manuals. You can also use msdn&nbsp; :). I don&#039;t&nbsp; think they differ between compilers (the simd ones).<br /><br /><div class="quote"><br />Anyway, I&#039;ve included your code in my test bed. My goal was to write several variants for the dot product, not only for that special case of a vector length of 256. The main program defines 2 floating point vectors (aligned by 16), calls the 6 different functions 5 million times and measures the time. It&#039;s written in C++ and with gcc inline assembler. It compiles with gcc 3.4.5 and better. I made timings under WinXP and Linux (both 32 bit).<br /></div>It would also be interesting to see how great auto-vectorization is in the newer versions of gcc. I don&#039;t have a newer version installed here atm. <br /><br /><div class="quote">The trick is, that my forum account doesnt allow attachments.<br /></div>Doesn&#039;t allow attachments? I don&#039;t know if there are any restrictions for new members, attaching works for me. Just don&#039;t click preview when you choose a file, go directly to submit.<br /></div>
    <div class="attachments">Attachments:
     <ul>
      <li><a href="../../attachments/?id=3247" target="_blank">test.txt</a></li>
     </ul>
    </div>
    <div class="meta">Posted on 2010-08-15 15:18:41 by drizz</div>
   </div>
   <div class="post" id="post-212706">
    <div class="subject"><a href="#post-212706">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote"><br />I don&#039;t know if there are any restrictions for new members, attaching works for me.<br /></div><br /><br />Yes, there are. Once a new member reaches 5 posts, in which ensures a greater certainty that they are not a spam-bot, the restriction is released.</div>
    <div class="meta">Posted on 2010-08-15 15:38:49 by SpooK</div>
   </div>
   <div class="post" id="post-212714">
    <div class="subject"><a href="#post-212714">Re: Fast Dot Product</a></div>
    <div class="body">Hallo drizz,<br /><br /><div class="quote">Yes, there are. Once a new member reaches 5 posts, in which ensures a greater certainty that they are not a spam-bot, the restriction is released.</div><br /><br />So, you see: there are restrictions. Therefore, here is my proposal again. Send me your mail address, because I don&#039;t know, if and when that feature will be activated. Please call on me: it isn&#039;t spam, only source code. Really!<br /><br />By the way, after registration to that forum, I received a mail with that content:<br /><br /><div class="quote">Before you can login and start using the forum, your request will be reviewed and approved. When this happens, you will receive another email from this address.</div><br /><br />I did wait, and wait ... but it came no other mail. So, I had to send another mail after a few days, and now I&#039;m here. Never mind, I&#039;m patient. <br /><br /><div class="quote">It would also be interesting to see how great auto-vectorization is in the newer versions of gcc.</div><br /><br />I&#039;ll try that under Linux; there is gcc 4.1. installed. I hope it works.<br /><br />Gunther<br /><br /><br /><br /></div>
    <div class="meta">Posted on 2010-08-15 18:56:49 by Gunther</div>
   </div>
   <div class="post" id="post-212716">
    <div class="subject"><a href="#post-212716">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote"><br />So, you see: there are restrictions.<br /></div><br /><br />Look at your current post count, and my original statement.</div>
    <div class="meta">Posted on 2010-08-15 19:26:13 by SpooK</div>
   </div>
   <div class="post" id="post-212753">
    <div class="subject"><a href="#post-212753">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote">Please call on me: it isn&#039;t spam, only source code. Really! </div> I&#039;ve sent you a PM, though it would be better if post your code here.<br /><br /><div class="quote">Never mind, I&#039;m patient. </div> Are there unpatient programmers&nbsp;  :)</div>
    <div class="meta">Posted on 2010-08-17 07:56:20 by drizz</div>
   </div>
   <div class="post" id="post-212755">
    <div class="subject"><a href="#post-212755">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote">... though it would be better if post your code here.</div><br /><br />Right. I&#039;ll prepare the sources for uploading here. Please give me 1 or 2 days, because I&#039;ve to convert the inline assembler part into Intel syntax for better readability. That has the drawback that the source won&#039;t compile under MacOS X, but what the heck. May be, I make 2 different versions.<br /><br />Gunther<br /> </div>
    <div class="meta">Posted on 2010-08-17 09:24:22 by Gunther</div>
   </div>
   <div class="post" id="post-212758">
    <div class="subject"><a href="#post-212758">Re: Fast Dot Product</a></div>
    <div class="body">You don&#039;t have to I never said I can&#039;t read it.&nbsp; ;)</div>
    <div class="meta">Posted on 2010-08-17 10:12:49 by drizz</div>
   </div>
   <div class="post" id="post-212760">
    <div class="subject"><a href="#post-212760">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote">You don&#039;t have to I never said I can&#039;t read it.</div><br /><br />I know that, but what&#039;s with other members? My intention is to get ideas to improve the code.<br /><br />Gunther<br /></div>
    <div class="meta">Posted on 2010-08-17 11:14:47 by Gunther</div>
   </div>
   <div class="post" id="post-212773">
    <div class="subject"><a href="#post-212773">Re: Fast Dot Product</a></div>
    <div class="body">Hallo drizz and other interested members,<br /><br />here are the sources for the test program. The archive contains the following files:<br /><br /><ul><br /><li>results.pdf - contains the times and a description of the test environment.</li><br /><li>build_dotfloat.bat - batch file to compile the running EXE under Windows</li><br /><li>dotfloat.cpp - the main procedure</li><br /><li>dotfloatfa.cpp - the inline assembly functions</li><br /><li>dotfloatfc.cpp - C++ functions</li><br /><li>dotfloatintrin.cpp - C++ code with intrinsics, designed by drizz. Thank you for that again.</li><br /><li>features.cpp - code to check the available processor features, nothing exciting.</li><br /></ul> <br /><br />Compile the running application with gcc; before have a look into the batch file for the different compiler switches. That&#039;ll give also hints to build the application at the command line under UNIX based systems.<br /><br />The program will run under Linux, BSD, MacOS X and Windows (all 32 bit).<br /><br />The software is in experimental state; nothing is finished or the last word. Any proposals for improvements are highly welcome, also test results on other pltforms and different processors.<br /><br />Gunther<br /><br /><br /><br /><br /><br /></div>
    <div class="attachments">Attachments:
     <ul>
      <li><a href="../../attachments/?id=3248" target="_blank">dotfloat.zip</a></li>
     </ul>
    </div>
    <div class="meta">Posted on 2010-08-17 18:52:58 by Gunther</div>
   </div>
   <div class="post" id="post-212778">
    <div class="subject"><a href="#post-212778">Re: Fast Dot Product</a></div>
    <div class="body">Hi,<br /><br />First, few notes:<br /><br />- your asm is doing do-while loop, while c++ code&nbsp; uses for() loop<br />- your asm is assuming array lengths multiple of 4 8 16 while c++ code only knows x4, and fpu code x1 x2<br />- prebuilt binaries are needed for people who just want to post their test results. (mainly win users without gcc :))<br /><br />A &quot;trick&quot; to remove 1 lea/add from the loop<br /><br /><pre><code>;&nbsp; before the loop subtract pointers<br />sub eax,edx// subl %%edx,%%eax<br />lo:<br />...<br />movaps xmm0, ;; movaps (%%eax,%%edx), %%xmm0;; address evaluates to correct spot<br />mulps xmm0, ;; mulps (%%edx), %%xmm0;; other one normal<br />add edx,16;; addl $16,%%edx;; by increasing one you effectively increase both<br />...<br />jxx lo<br /></code></pre><br /><br />These are my results:<br /><pre><code>XP SP3, AMD Opteron 148 (~2.2GHz)<br /><br />Supported by Processor and installed Operating System:<br />------------------------------------------------------<br /><br />&nbsp;  Pentium 4 Instruction Set,<br /> + FPU (floating point unit) on chip,<br /> + support of FXSAVE and FXRSTOR,<br /> + 57 MMX Instructions,<br /> + 70 SSE (Katmai) Instructions,<br /> + 144 SSE2 (Willamette) Instructions,<br /> + 13 SSE3 (Prescott) Instructions.<br /><br /><br />Calculating the dot product in 6 different variations.<br />That&#039;ll take a little while ...<br /><br />Straight forward C++ implementation (FPU Code):<br />-----------------------------------------------<br /><br />Dot Product 1 = 2867507200.00<br />Elapsed Time&nbsp; = 18.84 Seconds<br /><br />C++ implementation (FPU Code - 2 Accumulators):<br />-----------------------------------------------<br /><br />Dot Product 2 = 2867507200.00<br />Elapsed Time&nbsp; = 9.45 Seconds<br /><br />C++ Code with intrinsics (Original Code by Drizz):<br />--------------------------------------------------<br /><br />Dot Product 3 = 2867507200.00<br />Elapsed Time&nbsp; = 4.77 Seconds<br /><br />Simple SSE2 Code (1 Accumulator - 4 elements per cycle):<br />--------------------------------------------------------<br /><br />Dot Product 4 = 2867507200.00<br />Elapsed Time&nbsp; = 4.83 Seconds<br /><br />Solid SSE2 Code (2 Accumulators - 8 elements per cycle):<br />--------------------------------------------------------<br /><br />Dot Product 5 = 2867507200.00<br />Elapsed Time&nbsp; = 3.22 Seconds<br /><br />Better SSE2 Code (2 Accumulators - 16 elements per cycle):<br />----------------------------------------------------------<br /><br />Dot Product 6 = 2867507200.00<br />Elapsed Time&nbsp; = 2.91 Seconds</code></pre><br /><br />You said you have other functions too ? Theres little you can do with mul+add loop.<br /><br /></div>
    <div class="meta">Posted on 2010-08-17 21:42:54 by drizz</div>
   </div>
   <div class="post" id="post-212789">
    <div class="subject"><a href="#post-212789">Re: Fast Dot Product</a></div>
    <div class="body">Drizz,<br /><br />thank you for the posted results and your remarks.<br /><br /><div class="quote">- your asm is assuming array lengths multiple of 4 8 16 while c++ code only knows x4, and fpu code x1 x2</div><br /><br />Right. I coded that special case, to show the principle. A generic implementation should test that, of course. But as I wrote before:<br /><br /><div class="quote">The software is in experimental state; nothing is finished or the last word.</div><br /><br /><div class="quote">- prebuilt binaries are needed for people who just want to post their test results. (mainly win users without gcc)</div><br /><br />Do you mean the running EXE for Windows? With Unix (Linux, BSD and MacOS X) that isn&#039;t necessary, because a version of GCC should be available by default. Is it possible to replace the archive with that added file?<br /><br /><div class="quote">A &quot;trick&quot; to remove 1 lea/add from the loop</div><br /><br />I&#039;ll think about that. But you know that both registers point to different memory locations?<br /><br /><div class="quote">You said you have other functions too ?</div><br /><br />Yes, but those are not the point. Simple arithmetic mean etc. But the dot product is tricky. It must not be calculated once per call, but eight times. That has to do with the algorithm, which contains rotations and mirroring of an image part. Therefore: every saved nano second counts.<br /><br />Gunther<br /><br /><br /><br /><br /><br /><br /></div>
    <div class="meta">Posted on 2010-08-18 07:41:07 by Gunther</div>
   </div>
   <div class="post" id="post-212825">
    <div class="subject"><a href="#post-212825">Re: Fast Dot Product</a></div>
    <div class="body"><div class="quote">Do you mean the running EXE for Windows? With Unix (Linux, BSD and MacOS X) that isn&#039;t necessary, because a version of GCC should be available by default. Is it possible to replace the archive with that added file?</div> 1)Yes. 2)I know. 3)Yes <br /><br /><div class="quote"><br /><div class="quote">A &quot;trick&quot; to remove 1 lea/add from the loop</div><br />But you know that both registers point to different memory locations?<br /></div> Yes. Memory address is first calculated then accessed (  &lt;- any combination you like, except scale which must be 0,1,2,4,8 )<br />So:<br />Z = X - Y<br />Z + Y = X<br />(EDIT: forgot to write: modulo 2^32)<br /><br />LESS_ATT<sup>TM</sup> &nbsp;8)<br /><pre><code>float DotXMM2Acc16E_v2(float X&#91;],float Y&#91;],unsigned int m)<br />{<br />	#define AS(...) #__VA_ARGS__ &quot;\n\t&quot;<br />	__asm__ __volatile__(<br />	AS ( .set xmm0,%%xmm0		)<br />	AS ( .set xmm1,%%xmm1		)<br />	AS ( .set xmm2,%%xmm2		)<br />	AS ( .set xmm3,%%xmm3		)<br />	AS ( .set xmm4,%%xmm4		)<br />	AS ( .set xmm5,%%xmm5		)<br />	AS ( .set xmm6,%%xmm6		)<br />	AS ( .set xmm7,%%xmm7		)<br />	AS ( .set eax,%%eax		)<br />	AS ( .set edx,%%edx		)<br />	AS ( .set ecx,%%ecx		)<br />	AS ( .set esp,%%esp		)<br />	AS ( .set sub,subl		)<br />	AS ( .set mov,movl		)<br />	AS ( .set lea,leal		)<br /><br />	AS ( pxor xmm4,xmm4		)<br />	<br />	// sums are in xmm4 and xmm5<br />	<br />	AS ( mov 12(esp),ecx		) //ecx = n<br />	AS ( mov 4(esp),eax 		) //eax -&gt; X<br />	AS ( mov 8(esp),edx 		) //edx -&gt; Y<br />	AS ( pxor xmm5,xmm5 		)<br />	AS ( shl $2,ecx			) //ecx = 4*n (float)<br />	AS ( sub $4,esp			) //function result<br />	AS ( sub edx,eax		) // &lt;--------------------------------<br />	<br />	// init pattern 1. iteration<br />	<br />	AS ( movaps (eax,edx),xmm0	) //xmm0 = X<em> X<em> X<em> X<em> &lt;--------- etc.<br />	AS ( movaps 16(eax,edx),xmm1	) //xmm1 = X<em> X<em> X<em> X<em><br />	AS ( mulps (edx),xmm0 		) //xmm0 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( sub $64,ecx		) //we need n-1 iterations<br />	AS ( jz 2f 			) //jump: only 16 elements<br />	<br />	// main loop pattern<br />	<br />	AS ( .align	16 		)		<br />	AS ( 1:				)<br />	AS ( movaps	32(eax,edx),xmm2) //xmm2 = X<em> X<em> X<em> X<em><br />	AS ( mulps	16(edx),xmm1	) //xmm1 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( addps	xmm0,xmm4 	) //sum up<br />	AS ( movaps	48(eax,edx),xmm3) //xmm3 = X<em> X<em> X<em> X<em><br />	AS ( mulps	32(edx),xmm2	) //xmm2 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( addps	xmm1,xmm5 	) //sum up<br />	AS ( movaps	64(eax,edx),xmm0) //xmm0 = X<em> X<em> X<em> X<em><br />	AS ( mulps	48(edx),xmm3	) //xmm3 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( lea	64(edx),edx	) //update Y pointer<br />	AS ( addps	xmm2,xmm4 	) //sum up<br />	AS ( movaps	16(eax,edx),xmm1) //xmm1 = X<em> X<em> X<em> X<em><br />	AS ( mulps	(edx),xmm0 	) //xmm0 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( addps	xmm3,xmm5 	) //sum up<br />	AS ( sub	$64,ecx 	) //count down<br />	AS ( jnz 	1b 		)	<br />	<br />	// exit pattern last iteration<br />	<br />	AS ( 2:								)<br />	AS ( movaps 32(eax,edx),xmm2	) //xmm2 = X<em> X<em> X<em> X<em><br />	AS ( mulps 16(edx),xmm1		) //xmm1 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( addps xmm0,xmm4 		) //sum up<br />	AS ( movaps 48(eax,edx),xmm3	) //xmm3 = X<em> X<em> X<em> X<em><br />	AS ( mulps 32(edx),xmm2		) //xmm2 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( addps xmm1,xmm5 		) //sum up<br />	AS ( mulps 48(edx),xmm3		) //xmm3 = X<em>*Y<em> X<em>*Y<em> X<em>*Y<em> X<em>*Y<em><br />	AS ( addps xmm2,xmm4 		) //sum up<br />	AS ( addps xmm3,xmm5 		) //sum up<br />	<br />	// horizontal addition<br />	<br />	AS ( addps xmm5,xmm4		) //sum in xmm4<br />	AS ( movhlps xmm4,xmm0 		) //get bits 64 - 127 from xmm4<br />	AS ( addps xmm0,xmm4		) //sums in 2 dwords<br />	AS ( pshufd $1,xmm4,xmm0	) //get bits 32 - 63 from xmm4<br />	AS ( addss xmm0,xmm4		) //sum in 1 dword<br />	AS ( movss xmm4,(esp)		) //store sum<br />	AS ( flds (esp)			) //load function result<br />	AS ( sub $-4,esp		) //adjust stack<br />	AS ( ret			)					<br />	:<br />	:&quot;g&quot;(m)<br />	:&quot;%ecx&quot;,&quot;%eax&quot;,&quot;%edx&quot;<br />	);<br />}<br />- adjusted tabs for display on the forum<br /></code></pre><br /><br />removing 1 lea saves ~0.14 sec </div>
    <div class="meta">Posted on 2010-08-19 10:23:54 by drizz</div>
   </div>
<form class="pagination" action="../" method="get"><a href="../?id=30153&amp;page=1" style="visibility:hidden;">&laquo;</a><a href="../?id=30153&amp;page=0" style="visibility:hidden;">&lt;</a><input type="hidden" name="id" value="30153" /><input type="number" name="page" min="1" max="2" step="1" value="1" onchange="this.form.submit();" /><a href="../?id=30153&amp;page=2">&gt;</a><a href="../?id=30153&amp;page=2">&raquo;</a></form>  </div>
 </body>
</html>