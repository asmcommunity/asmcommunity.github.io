<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8" />
  <title>Uniform Binary Format vs. Source Code - Forums - ASM Community</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" />
  <link rel="canonical" href="../?id=21183" />
     </head>
 <body>
  <div id="header">
   <h1><a href="../../../">ASM Community</a></h1>
  </div>
  <div id="content">
   <p class="breadcrumbs"><a href="../../../">Home</a> &raquo; <a href="../../">Forums</a> &raquo; <a href="../../board/?id=12">The Heap</a> &raquo; <a href="../?id=21183">Uniform Binary Format vs. Source Code</a></p>
   <div class="post" id="post-160367">
    <div class="subject"><a href="#post-160367">Uniform Binary Format vs. Source Code</a></div>
    <div class="body">Just interesting questions I have been pondering.<br /><br />-If all CPU structures and instructions follow the same basic premise of logic and math, how hard would it be to create a uniform/universal type of assembly language conversion/compilation to generically encompass these architectures?<br />-How much different would it be from the logical structuring of source code compilation?<br />-How difficult would it be to optimize for specific architectures as compared to source code?<br /><br />I would like to see suggestions/expanions of these ideas :)</div>
    <div class="meta">Posted on 2005-05-23 05:33:48 by SpooK</div>
   </div>
   <div class="post" id="post-160376">
    <div class="subject"><a href="#post-160376">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">I think those are the questions that made programmers come up with CPU emulators and cross-compilers. I think these two items take care of all your questions.<br /><br />1. How hard would it be? It&#39;s not really that hard nowadays since our hardware speed, memory and storage are sufficient to handle multiple copies of different CPU and OS emulations at the same time.<br />2. All it takes to compile for a new CPU is to add the support into the compiler. gcc has support for many processors.<br />3. See previous answer.<br /><br />Thus, the deltas or differences between different CPU architectures can easily be seen by the coding it takes to accommodate that particular CPU within an existing CPU emulator or compiler.</div>
    <div class="meta">Posted on 2005-05-23 13:00:28 by Kdr Kane</div>
   </div>
   <div class="post" id="post-160414">
    <div class="subject"><a href="#post-160414">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body"><div class="quote"><br />-If all CPU structures and instructions follow the same basic premise of logic and math, how hard would it be to create a uniform/universal type of assembly language conversion/compilation to generically encompass these architectures?<br /></div><br /><br />You mean a syntax to use in source code, or a binary bytecode produced by a compiler?</div>
    <div class="meta">Posted on 2005-05-24 14:25:30 by QvasiModo</div>
   </div>
   <div class="post" id="post-160415">
    <div class="subject"><a href="#post-160415">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">Both really. A generic architecture/bytecode is the main goal, but not necessarily to be interpretated directly. I am also talking about the assembly instructions to represent that architecture.</div>
    <div class="meta">Posted on 2005-05-24 14:33:00 by SpooK</div>
   </div>
   <div class="post" id="post-160416">
    <div class="subject"><a href="#post-160416">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">It&#39;s funny, I&#39;ve been pondering about this too... :)<br /><br />One problem I found with a generic bytecode is the need for some specific implementation details, like parameter passing conventions for example. That would make the generic architecture *very* abstract, as you&#39;d have to represent functionality at a higher level than a simple sequence of opcodes.</div>
    <div class="meta">Posted on 2005-05-24 14:38:59 by QvasiModo</div>
   </div>
   <div class="post" id="post-160417">
    <div class="subject"><a href="#post-160417">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">Well, most architectures I know have support for this through the use of the stack or something similar.</div>
    <div class="meta">Posted on 2005-05-24 14:54:26 by SpooK</div>
   </div>
   <div class="post" id="post-160421">
    <div class="subject"><a href="#post-160421">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">But not all. I understand Alpha processors use registers. Also Linux syscalls do. IMHO to make it compatible with everything you&#39;d need an opcode for function calls. Then another program would convert this generic bytecode into native code, and decide which calling convention to use in each case.<br /><br />I couldn&#39;t come up with other such examples (save from direct hardware access, etc), but I suppose ther could be other problems I didn&#39;t think of yet... :?:<br /><br />It&#39;s an interesting topic. :)</div>
    <div class="meta">Posted on 2005-05-24 16:06:40 by QvasiModo</div>
   </div>
   <div class="post" id="post-160476">
    <div class="subject"><a href="#post-160476">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">Processors aren&#39;t so much the same, instruction-set-wise. Implementing a universal assembler won&#39;t be optimization-friendly imho. A C/C++ compiler will <strong>always</strong> beat it. <br /><br />I&#39;ll just state some major differences in the ARM cpu, compared to x86:<br />ARM has conditional execution flags in each instruction. <br />Also, a bit in each instruction specifies whether you really want to change the flags atm. <br />16 registers available - but directly manipulating memory is limited to just load/store. <br />Return address is not on stack, but in a register.<br />The stack is a mess. There are be 4 types of it (post-increment, pre-increment,&nbsp; post-decrement,pre-decrement), OS vendors decide which to use - and coders have to conform. <br />Reading data from unaligned address crashes the cpu<br />No exception-handling<br />Procedure arguments are: first 4 are in registers, the others - on stack. <br />Push/pop - two types of them <br />Little-endian/Big-endian troubles. <br />Constants in any instruction are limited to 8-bit, rotated by 5 more bits in the instruction<br />The above means that with call/jmp (actually named BL/B) instructions you can&#39;t directly jump to absolutely any part of your code. <br />Data-processing instructions are not like &quot;add destination,source&quot; , but &quot;add destination, source1, source2&quot;&nbsp; (destination = source1 + source2)<br />And many more major differences ... T_T . I wonder who once told me ARM is like x86 ^^&quot;. <br /><br />I use macros to make my ARM PalmOS code directly portable to ARM WindowsCE . Since Microsoft and PalmSource have decided on different approaches in stack/proccall/data_addressing. But that&#39;s the limit of making a portable assembler - macros for conforming different standards/approaches on the same cpu. <br /><br />Anyway, <strong>my definite conclusion</strong> - assemblers are cpu-specific, and they should stay like that. If you want portability, code in C . <br /></div>
    <div class="meta">Posted on 2005-05-26 11:08:04 by Ultrano</div>
   </div>
   <div class="post" id="post-160486">
    <div class="subject"><a href="#post-160486">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">Like I suspected... the level of abstraction needed to make the code protable would turn this &quot;portable assembler&quot; into a full high level language. Too bad, it would have been cool...</div>
    <div class="meta">Posted on 2005-05-26 17:41:02 by QvasiModo</div>
   </div>
   <div class="post" id="post-160489">
    <div class="subject"><a href="#post-160489">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">There would be no doubt that it would need to &quot;compile&quot; for anything to work, I was just wondering what the difference would be between C and an uniform assembly language in such a manner. Thanks Ultrano.</div>
    <div class="meta">Posted on 2005-05-26 17:51:47 by SpooK</div>
   </div>
   <div class="post" id="post-212224">
    <div class="subject"><a href="#post-212224">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">Very old topic, I know... just had never seen it before.<br />I&#039;d like to add two things here.<br />First... in my circle of programming friends, we always used to refer to C as &#039;portable assembly&#039;... because in a way that&#039;s what it is. It abstracts away architectural differences such as registers and the actual machinecode, but still allows you to use all the common operations for every CPU.<br /><br />Second... universal bytecode is something that is used by most modern compilers. The compiling is done in two stages. The first stage is generic for all architectures... parsing of the sourcecode into an expression tree, and doing global optimizations etc.<br />This results in a list of universal bytecode, which is then sent to the architecture-specific backend to generate the native machinecode.<br /><br />In the case of Java and .NET, they simply cut the compiler in half, where the sourcecode is compiled to universal bytecode and stored like that in the &#039;binaries&#039;. The conversion to architecture-specific code is done in the &#039;virtual machine&#039;.<br />There are tools to program &#039;assembly&#039; in Java or .NET bytecode directly, but there is virtually no gain over using a high-level language, since the universal bytecode is so generic. The only reason why assembly can be smaller/faster/etc than C is because you can exploit architecture-specific features. Universal code would eliminate this by default.</div>
    <div class="meta">Posted on 2010-07-06 04:14:02 by Scali</div>
   </div>
   <div class="post" id="post-212225">
    <div class="subject"><a href="#post-212225">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">interesting topic.<br /><br />i think that having a universal asm that will run on standardized cpus would be a blessing for programmer, eg the &quot;ground troops&quot;, but guys who sell software and hardware simply wont wear it...<br /><br />its simply not worth it economically (unless this would be a monopolization of hardware or asm by, say, guys like ms).<br />but would they all agree out of free will to make things easier for programmers? bloody never. <br />becouse their goal is not quolity, or speed, or proficiency, but simply large sums of greenbacks. <br /><br /><br />Big guys up there want to rule. you can&#039;t rule, if all is the same.</div>
    <div class="meta">Posted on 2010-07-06 10:58:06 by Turnip</div>
   </div>
   <div class="post" id="post-212227">
    <div class="subject"><a href="#post-212227">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body"><div class="quote"><br />but guys who sell software and hardware simply wont wear it...<br /></div><br /><br />For the consumer market, never.<br /><br />I suppose with PCI Express, FPGA&#039;s and the like, you can rig something together that wouldn&#039;t be too horribly bad.<br /><br />However, and as Scali said, this is an old topic, and stuff like LLVM trumps this concept through and through.</div>
    <div class="meta">Posted on 2010-07-06 12:27:51 by SpooK</div>
   </div>
   <div class="post" id="post-212231">
    <div class="subject"><a href="#post-212231">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body"><div class="quote">i think that having a universal asm that will run on standardized cpus would be a blessing for programmer</div>Why?<br /><br />Most programmers don&#039;t program at the assembly level, and the ones that do (hopefully!) do it for a reason, and want to take advantage of what our CPUs can do... instead of writing crap lowest-common-denominator code.</div>
    <div class="meta">Posted on 2010-07-06 15:43:41 by f0dder</div>
   </div>
   <div class="post" id="post-212239">
    <div class="subject"><a href="#post-212239">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">just my opinion.<br />i would prefer learning one thing and be welcome as an expert, then standing on a cross road, which changes with every second.<br />and porting would be easier, won&#039;t it?</div>
    <div class="meta">Posted on 2010-07-07 01:50:46 by Turnip</div>
   </div>
   <div class="post" id="post-212240">
    <div class="subject"><a href="#post-212240">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body"><div class="quote"><br />i think that having a universal asm that will run on standardized cpus would be a blessing for programmer, eg the &quot;ground troops&quot;, but guys who sell software and hardware simply wont wear it...</div><br /><br />I suppose you could argue that x86 is so commonplace that it&#039;s already &#039;universal asm&#039;.</div>
    <div class="meta">Posted on 2010-07-07 01:59:33 by Scali</div>
   </div>
   <div class="post" id="post-212243">
    <div class="subject"><a href="#post-212243">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">perhaps you are right. but it doesn&#039;t stop companies personalizing it in any way possible. <br />there is masm, tasm, fasm, blah-blah - asm etc.<br />and is it so important for at&amp;t to have syntax not like intel? </div>
    <div class="meta">Posted on 2010-07-07 05:59:40 by Turnip</div>
   </div>
   <div class="post" id="post-212246">
    <div class="subject"><a href="#post-212246">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">You&#039;re confusing dialects of the same language (NASM/MASM/TASM/etc) for different languages (x86/MIPS/ARM/etc). This discussion was originally about unifying the languages, not the dialects.<br /><br />As for companies, it was less about personalizing the language as a dialect as it was about having a working tool-chain designed around your development staff.</div>
    <div class="meta">Posted on 2010-07-07 11:54:51 by SpooK</div>
   </div>
   <div class="post" id="post-212248">
    <div class="subject"><a href="#post-212248">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">i am simply illustrating that if they cant even have a standardized version of x86 dialect (ms has masm, borland has tasm etc) how can we expect them join their forces volontarily, when they are bitter enemies on the free market.<br /><br />personally i am a great admirer of open standards. <br /><br />i have also seen outsource companies quickly adapting their employees&nbsp; (and tool-chain) to whatever technology is in favor this year (month, etc) . So i believe, that at&amp;t could use intel style, if this wouldn&#039;t mean also loosing a few kudos )))</div>
    <div class="meta">Posted on 2010-07-07 12:13:00 by Turnip</div>
   </div>
   <div class="post" id="post-212252">
    <div class="subject"><a href="#post-212252">Re: Uniform Binary Format vs. Source Code</a></div>
    <div class="body">AT&amp;T syntax is actually older than x86.<br />There is something to say for AT&amp;T syntax. Partly it was designed to make assemblers as simple as possible to write... part of it is also architecture-independent (for example, 68k asm in AT&amp;T syntax is very similar to x86 asm in AT&amp;T syntax). It&#039;s also a very unambiguous syntax.<br />Perhaps not very user-friendly though.</div>
    <div class="meta">Posted on 2010-07-08 05:41:27 by Scali</div>
   </div>
  </div>
 </body>
</html>